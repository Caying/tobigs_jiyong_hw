{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 반갑습니다 13기 여러분\n",
    "\n",
    "과제를 진행해 볼게요\n",
    "\n",
    "혹시라도 도저히 모르겠거나 해결이 안되신다면 01040493041로 전화주시거나 카톡주세요!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ''' ? ''' 이 있는 부분을 채워주시면 됩니다\n",
    "\n",
    "나는 내 스타일로 하겠다 하시면 그냥 구현 하셔도 됩니다!!\n",
    "\n",
    "참고하셔야 하는 함수들은 링크 달아드렸으니 들어가서 확인해보세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) PCA의 과정을 한번 차근차근 밟아 볼거에요 잘 따라 오세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as lin\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#   기본 모듈들을 불러와 줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [95, 91, 66, 94, 68, 63, 12, 73, 93, 51, 13, 70, 63, 63, 97, 56, 67, 96, 75, 6]\n",
    "x2 = [56, 27, 25, 1, 9, 80, 92, 69, 6, 25, 83, 82, 54, 97, 66, 93, 76, 59, 94, 9]\n",
    "x3 = [57, 34, 9, 79, 4, 77, 100, 42, 6, 96, 61, 66, 9, 25, 84, 46, 16, 63, 53, 30]\n",
    "\n",
    "#   설명변수 x1, x2, x3의 값이 이렇게 있네요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack((x1,x2,x3),axis=0)\n",
    "\n",
    "#   설명변수들을 하나의 행렬로 만들어 줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X.T,columns=['x1','x2','x3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>92</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>73</td>\n",
       "      <td>69</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>51</td>\n",
       "      <td>25</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>83</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>70</td>\n",
       "      <td>82</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>63</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>63</td>\n",
       "      <td>97</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>56</td>\n",
       "      <td>93</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>67</td>\n",
       "      <td>76</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>96</td>\n",
       "      <td>59</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>75</td>\n",
       "      <td>94</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1  x2   x3\n",
       "0   95  56   57\n",
       "1   91  27   34\n",
       "2   66  25    9\n",
       "3   94   1   79\n",
       "4   68   9    4\n",
       "5   63  80   77\n",
       "6   12  92  100\n",
       "7   73  69   42\n",
       "8   93   6    6\n",
       "9   51  25   96\n",
       "10  13  83   61\n",
       "11  70  82   66\n",
       "12  63  54    9\n",
       "13  63  97   25\n",
       "14  97  66   84\n",
       "15  56  93   46\n",
       "16  67  76   16\n",
       "17  96  59   63\n",
       "18  75  94   53\n",
       "19   6   9   30"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-1) 먼저 PCA를 시작하기 전에 항상!!!!!! 데이터를 scaling 해주어야 해요\n",
    "\n",
    "https://datascienceschool.net/view-notebook/f43be7d6515b48c0beb909826993c856/ 를 참고하시면 도움이 될거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.08573604,  0.02614175,  0.30684189],\n",
       "       [ 0.93801686, -0.86575334, -0.46445467],\n",
       "       [ 0.01477192, -0.92726334, -1.30282049],\n",
       "       [ 1.04880625, -1.66538341,  1.04460382],\n",
       "       [ 0.08863151, -1.41934339, -1.47049366],\n",
       "       [-0.09601747,  0.76426183,  0.97753455],\n",
       "       [-1.97943714,  1.13332186,  1.74883111],\n",
       "       [ 0.2732805 ,  0.42595679, -0.1961776 ],\n",
       "       [ 1.01187645, -1.5116084 , -1.40342439],\n",
       "       [-0.53917504, -0.92726334,  1.61469258],\n",
       "       [-1.94250735,  0.85652683,  0.44098042],\n",
       "       [ 0.16249111,  0.82577183,  0.60865359],\n",
       "       [-0.09601747, -0.03536825, -1.30282049],\n",
       "       [-0.09601747,  1.28709688, -0.76626636],\n",
       "       [ 1.15959564,  0.33369178,  1.21227698],\n",
       "       [-0.35452606,  1.16407687, -0.06203907],\n",
       "       [ 0.05170172,  0.64124181, -1.06807806],\n",
       "       [ 1.12266584,  0.11840676,  0.50804969],\n",
       "       [ 0.3471401 ,  1.19483187,  0.17270336],\n",
       "       [-2.20101593, -1.41934339, -0.5985932 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_std.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.08573604,  0.93801686,  0.01477192,  1.04880625,  0.08863151,\n",
       "        -0.09601747, -1.97943714,  0.2732805 ,  1.01187645, -0.53917504,\n",
       "        -1.94250735,  0.16249111, -0.09601747, -0.09601747,  1.15959564,\n",
       "        -0.35452606,  0.05170172,  1.12266584,  0.3471401 , -2.20101593],\n",
       "       [ 0.02614175, -0.86575334, -0.92726334, -1.66538341, -1.41934339,\n",
       "         0.76426183,  1.13332186,  0.42595679, -1.5116084 , -0.92726334,\n",
       "         0.85652683,  0.82577183, -0.03536825,  1.28709688,  0.33369178,\n",
       "         1.16407687,  0.64124181,  0.11840676,  1.19483187, -1.41934339],\n",
       "       [ 0.30684189, -0.46445467, -1.30282049,  1.04460382, -1.47049366,\n",
       "         0.97753455,  1.74883111, -0.1961776 , -1.40342439,  1.61469258,\n",
       "         0.44098042,  0.60865359, -1.30282049, -0.76626636,  1.21227698,\n",
       "        -0.06203907, -1.06807806,  0.50804969,  0.17270336, -0.5985932 ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-2) 자 그럼 공분산 행렬을 구해볼게요\\\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.cov.html 를 참고하시면 도움이 될거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cov_matrix = np.cov(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.05263158, -0.2037104 , -0.12079228],\n",
       "       [-0.2037104 ,  1.05263158,  0.3125801 ],\n",
       "       [-0.12079228,  0.3125801 ,  1.05263158]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-3) 이제 고유값과 고유벡터를 구해볼게요\n",
    "\n",
    "방법은 실습코드에 있어요!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues = lin.eig(cov_matrix)[0]\n",
    "eigenvectors = lin.eig(cov_matrix)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.48756162 0.94435407 0.72597904]\n",
      "[[ 0.47018528 -0.85137353 -0.23257022]\n",
      " [-0.64960236 -0.15545725 -0.74421087]\n",
      " [-0.59744671 -0.50099516  0.62614797]]\n"
     ]
    }
   ],
   "source": [
    "print(eigenvalues)\n",
    "print(eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.zeros((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat[0][0] = eigenvalues[0]\n",
    "mat[1][1] = eigenvalues[1]\n",
    "mat[2][2] = eigenvalues[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.48756162, 0.        , 0.        ],\n",
       "       [0.        , 0.94435407, 0.        ],\n",
       "       [0.        , 0.        , 0.72597904]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-4) 자 이제 고유값 분해를 할 모든 준비가 되었어요 고유값 분해의 곱으로 원래 공분산 행렬을 구해보세요\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html 를 참고해서 행렬 끼리 곱하시면 됩니다\n",
    "\n",
    "행렬 곱으로 eigenvector x mat x eigenvector.T 하면 될거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.05263158, -0.2037104 , -0.12079228],\n",
       "       [-0.2037104 ,  1.05263158,  0.3125801 ],\n",
       "       [-0.12079228,  0.3125801 ,  1.05263158]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.dot(eigenvectors,mat),eigenvectors.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-5) 마지막으로 고유 벡터 축으로 값을 변환해 볼게요\n",
    "\n",
    "함수로 한번 정의해 보았어요\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_coordinates(X,eigenvectors):\n",
    "    for i in range(eigenvectors.shape[0]):\n",
    "        if i == 0:\n",
    "            new = [X.dot(eigenvectors.T[i])]\n",
    "        else:\n",
    "            new = np.concatenate((new, [X.dot(eigenvectors.T[i])]),axis=0)\n",
    "    return new.T\n",
    "\n",
    "# 모든 고유 벡터 축으로 데이터를 projection한 값입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31019368, -1.08215716, -0.07983642],\n",
       "       [ 1.28092404, -0.43132556,  0.13533091],\n",
       "       [ 1.38766381,  0.78428014, -0.12911446],\n",
       "       [ 0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [ 1.84222365,  0.88189889,  0.11493111],\n",
       "       [-1.12563709, -0.52680338,  0.06564012],\n",
       "       [-2.71174416,  0.63290138,  0.71195473],\n",
       "       [-0.03100441, -0.20059783, -0.50339479],\n",
       "       [ 2.29618509,  0.07661447,  0.01087174],\n",
       "       [-0.61585248, -0.205764  ,  1.82651199],\n",
       "       [-1.73320252,  1.29971699,  0.09045178],\n",
       "       [-0.82366049, -0.57164535, -0.27123176],\n",
       "       [ 0.75619512,  0.73995175, -0.76710616],\n",
       "       [-0.42344386,  0.26555394, -1.41533681],\n",
       "       [-0.39581307, -1.64646874,  0.24104031],\n",
       "       [-0.88581498,  0.15195119, -0.82271209],\n",
       "       [ 0.24587691,  0.39139878, -1.15801831],\n",
       "       [ 0.14741103, -1.22874561, -0.03110396],\n",
       "       [-0.7161265 , -0.56781471, -0.86180345],\n",
       "       [ 0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_coordinates(X_std,eigenvectors)\n",
    "\n",
    "# 새로운 축으로 변환되어 나타난 데이터들입니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) PCA를 구현해 보세요\n",
    "\n",
    "위의 과정을 이해하셨다면 충분히 하실 수 있을거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def MYPCA(X,number):\n",
    "    scaler = StandardScaler()\n",
    "    x_std = scaler.fit_transform(X)\n",
    "    features = x_std.T\n",
    "    cov_matrix = np.cov(features)\n",
    "    \n",
    "    eigenvalues = lin.eig(cov_matrix)[0]\n",
    "    eigenvectors = lin.eig(cov_matrix)[1]\n",
    "    \n",
    "    new_coordinates(x_std,eigenvectors)\n",
    "    \n",
    "    new_coordinate = new_coordinates(x_std,eigenvectors)\n",
    "    \n",
    "    index = eigenvalues.argsort()\n",
    "    index = list(index)\n",
    "    \n",
    "    for i in range(number):\n",
    "        if i==0:\n",
    "            new = [new_coordinate[:,index.index(i)]]\n",
    "        else:\n",
    "            new = np.concatenate(([new_coordinate[:,index.index(i)]],new),axis=0)\n",
    "    return new.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31019368, -1.08215716, -0.07983642],\n",
       "       [ 1.28092404, -0.43132556,  0.13533091],\n",
       "       [ 1.38766381,  0.78428014, -0.12911446],\n",
       "       [ 0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [ 1.84222365,  0.88189889,  0.11493111],\n",
       "       [-1.12563709, -0.52680338,  0.06564012],\n",
       "       [-2.71174416,  0.63290138,  0.71195473],\n",
       "       [-0.03100441, -0.20059783, -0.50339479],\n",
       "       [ 2.29618509,  0.07661447,  0.01087174],\n",
       "       [-0.61585248, -0.205764  ,  1.82651199],\n",
       "       [-1.73320252,  1.29971699,  0.09045178],\n",
       "       [-0.82366049, -0.57164535, -0.27123176],\n",
       "       [ 0.75619512,  0.73995175, -0.76710616],\n",
       "       [-0.42344386,  0.26555394, -1.41533681],\n",
       "       [-0.39581307, -1.64646874,  0.24104031],\n",
       "       [-0.88581498,  0.15195119, -0.82271209],\n",
       "       [ 0.24587691,  0.39139878, -1.15801831],\n",
       "       [ 0.14741103, -1.22874561, -0.03110396],\n",
       "       [-0.7161265 , -0.56781471, -0.86180345],\n",
       "       [ 0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MYPCA(X,3)\n",
    "\n",
    "# 새로운 축으로 잘 변환되어서 나타나나요?\n",
    "# 위에서 했던 PCA랑은 차이가 있을 수 있어요 왜냐하면 위에서는 고유값이 큰 축 순서로 정렬을 안했었거든요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) sklearn이랑 비교를 해볼까요?\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html 를 참고하시면 도움이 될거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31019368, -1.08215716, -0.07983642],\n",
       "       [-1.28092404, -0.43132556,  0.13533091],\n",
       "       [-1.38766381,  0.78428014, -0.12911446],\n",
       "       [-0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [-1.84222365,  0.88189889,  0.11493111],\n",
       "       [ 1.12563709, -0.52680338,  0.06564012],\n",
       "       [ 2.71174416,  0.63290138,  0.71195473],\n",
       "       [ 0.03100441, -0.20059783, -0.50339479],\n",
       "       [-2.29618509,  0.07661447,  0.01087174],\n",
       "       [ 0.61585248, -0.205764  ,  1.82651199],\n",
       "       [ 1.73320252,  1.29971699,  0.09045178],\n",
       "       [ 0.82366049, -0.57164535, -0.27123176],\n",
       "       [-0.75619512,  0.73995175, -0.76710616],\n",
       "       [ 0.42344386,  0.26555394, -1.41533681],\n",
       "       [ 0.39581307, -1.64646874,  0.24104031],\n",
       "       [ 0.88581498,  0.15195119, -0.82271209],\n",
       "       [-0.24587691,  0.39139878, -1.15801831],\n",
       "       [-0.14741103, -1.22874561, -0.03110396],\n",
       "       [ 0.7161265 , -0.56781471, -0.86180345],\n",
       "       [-0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31019368, -1.08215716, -0.07983642],\n",
       "       [ 1.28092404, -0.43132556,  0.13533091],\n",
       "       [ 1.38766381,  0.78428014, -0.12911446],\n",
       "       [ 0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [ 1.84222365,  0.88189889,  0.11493111],\n",
       "       [-1.12563709, -0.52680338,  0.06564012],\n",
       "       [-2.71174416,  0.63290138,  0.71195473],\n",
       "       [-0.03100441, -0.20059783, -0.50339479],\n",
       "       [ 2.29618509,  0.07661447,  0.01087174],\n",
       "       [-0.61585248, -0.205764  ,  1.82651199],\n",
       "       [-1.73320252,  1.29971699,  0.09045178],\n",
       "       [-0.82366049, -0.57164535, -0.27123176],\n",
       "       [ 0.75619512,  0.73995175, -0.76710616],\n",
       "       [-0.42344386,  0.26555394, -1.41533681],\n",
       "       [-0.39581307, -1.64646874,  0.24104031],\n",
       "       [-0.88581498,  0.15195119, -0.82271209],\n",
       "       [ 0.24587691,  0.39139878, -1.15801831],\n",
       "       [ 0.14741103, -1.22874561, -0.03110396],\n",
       "       [-0.7161265 , -0.56781471, -0.86180345],\n",
       "       [ 0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MYPCA(X,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) MNIST data에 적용을 해볼게요!\n",
    "\n",
    "mnist data를 따로 내려받지 않게 압축파일에 같이 두었어요~!!!\n",
    "\n",
    "mnist-original.mat 파일과 같은 위치에서 주피터 노트북을 열어주세요~!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as lin\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from scipy import io\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# mnist 손글씨 데이터를 불러옵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = io.loadmat('mnist-original.mat') \n",
    "X = mnist['data'].T\n",
    "y = mnist['label'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data information\n",
    "\n",
    "# 7만개의 작은 숫자 이미지\n",
    "# 행 열이 반대로 되어있음 -> 전치\n",
    "# grayscale 28x28 pixel = 784 feature\n",
    "# 각 picel은 0~255의 값\n",
    "# label = 1~10 label이 총 10개인거에 주목하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  pixel781  pixel782  pixel783\n",
       "0       0       0       0       0       0       0       0       0       0       0  ...         0         0         0         0         0         0         0         0         0         0\n",
       "1       0       0       0       0       0       0       0       0       0       0  ...         0         0         0         0         0         0         0         0         0         0\n",
       "2       0       0       0       0       0       0       0       0       0       0  ...         0         0         0         0         0         0         0         0         0         0\n",
       "3       0       0       0       0       0       0       0       0       0       0  ...         0         0         0         0         0         0         0         0         0         0\n",
       "4       0       0       0       0       0       0       0       0       0       0  ...         0         0         0         0         0         0         0         0         0         0\n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data를 각 픽셀에 이름붙여 표현\n",
    "feat_cols = [ 'pixel'+str(i) for i in range(X.shape[1]) ]\n",
    "df = pd.DataFrame(X,columns=feat_cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df에 라벨 y를 붙여서 데이터프레임 생성\n",
    "df['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  pixel781  pixel782  pixel783    y\n",
       "0           0       0       0       0       0       0       0       0       0       0  ...         0         0         0         0         0         0         0         0         0  0.0\n",
       "1           0       0       0       0       0       0       0       0       0       0  ...         0         0         0         0         0         0         0         0         0  0.0\n",
       "2           0       0       0       0       0       0       0       0       0       0  ...         0         0         0         0         0         0         0         0         0  0.0\n",
       "3           0       0       0       0       0       0       0       0       0       0  ...         0         0         0         0         0         0         0         0         0  0.0\n",
       "4           0       0       0       0       0       0       0       0       0       0  ...         0         0         0         0         0         0         0         0         0  0.0\n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...     ...  ...       ...       ...       ...       ...       ...       ...       ...       ...       ...  ...\n",
       "69995       0       0       0       0       0       0       0       0       0       0  ...         0         0         0         0         0         0         0         0         0  9.0\n",
       "69996       0       0       0       0       0       0       0       0       0       0  ...         0         0         0         0         0         0         0         0         0  9.0\n",
       "69997       0       0       0       0       0       0       0       0       0       0  ...         0         0         0         0         0         0         0         0         0  9.0\n",
       "69998       0       0       0       0       0       0       0       0       0       0  ...         0         0         0         0         0         0         0         0         0  9.0\n",
       "69999       0       0       0       0       0       0       0       0       0       0  ...         0         0         0         0         0         0         0         0         0  9.0\n",
       "\n",
       "[70000 rows x 785 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 지금까지 배운 여러 머신러닝 기법들이 있을거에요\n",
    "\n",
    "4-1) train_test_split을 통해 데이터를 0.8 0.2의 비율로 분할 해 주시고요\n",
    "\n",
    "4-2) PCA를 이용하여 mnist data를 축소해서 학습을 해주세요 / test error가 제일 작으신 분께 상품을 드리겠습니다 ^0^\n",
    "\n",
    "특정한 틀 없이 자유롭게 하시면 됩니다!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-1) train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, Test 셋 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56000, 784), (14000, 784), (56000, 1), (14000, 1))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.97707217e+02,  4.41592631e+02,  2.24780420e+02, ...,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 2.35057670e+02, -2.49316542e+02, -3.64063866e+02, ...,\n",
       "         2.15986327e-13, -2.24437861e-13, -1.20466211e-13],\n",
       "       [ 3.16018202e+02,  9.20309985e+02, -4.25732116e+02, ...,\n",
       "        -2.38949293e-13,  3.29038398e-13,  1.53453618e-13],\n",
       "       ...,\n",
       "       [ 3.02645638e+01,  9.57855086e+02, -2.25398268e+02, ...,\n",
       "        -3.11712629e-15,  4.59792393e-16, -2.53100900e-16],\n",
       "       [-7.91098421e+02, -1.77572090e+01,  2.31077320e+02, ...,\n",
       "        -3.42171503e-16, -4.00474581e-15,  1.06090774e-15],\n",
       "       [ 1.22699525e+02, -1.34553299e+02, -6.98784808e+02, ...,\n",
       "         5.42991749e-17, -5.18887971e-16,  6.67109197e-16]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance_ratio = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.904275\n",
       "dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(explained_variance_ratio[0:90])/np.sum(explained_variance_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bf9f874808>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "explained_variance_ratio = pd.DataFrame(explained_variance_ratio)\n",
    "sns.lineplot(data = explained_variance_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 45)\n",
    "X_train_pca_mnist = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca = PCA(n_components = 90)\n",
    "#X_train_pca_mnist = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance_ratio = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bf9f715fc8>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "explained_variance_ratio = pd.DataFrame(explained_variance_ratio)\n",
    "sns.lineplot(data = explained_variance_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_mnist = pd.DataFrame(X_train_pca_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca_mnist = pd.DataFrame(pca.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-884.023692</td>\n",
       "      <td>-526.779091</td>\n",
       "      <td>128.919388</td>\n",
       "      <td>206.082051</td>\n",
       "      <td>-208.260172</td>\n",
       "      <td>504.770928</td>\n",
       "      <td>-352.482747</td>\n",
       "      <td>-76.854877</td>\n",
       "      <td>216.296789</td>\n",
       "      <td>-49.642854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029621</td>\n",
       "      <td>-10.406068</td>\n",
       "      <td>145.718693</td>\n",
       "      <td>18.256846</td>\n",
       "      <td>54.591569</td>\n",
       "      <td>-13.047681</td>\n",
       "      <td>27.081955</td>\n",
       "      <td>-54.470397</td>\n",
       "      <td>-88.903501</td>\n",
       "      <td>170.139393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>257.098914</td>\n",
       "      <td>1027.080774</td>\n",
       "      <td>-411.141501</td>\n",
       "      <td>-401.603660</td>\n",
       "      <td>717.290205</td>\n",
       "      <td>-424.914873</td>\n",
       "      <td>114.042914</td>\n",
       "      <td>-211.447476</td>\n",
       "      <td>26.426887</td>\n",
       "      <td>357.251971</td>\n",
       "      <td>...</td>\n",
       "      <td>69.894517</td>\n",
       "      <td>11.006854</td>\n",
       "      <td>18.747626</td>\n",
       "      <td>-80.959883</td>\n",
       "      <td>2.856614</td>\n",
       "      <td>57.195134</td>\n",
       "      <td>14.413934</td>\n",
       "      <td>-33.451316</td>\n",
       "      <td>-126.965686</td>\n",
       "      <td>25.051057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-296.807408</td>\n",
       "      <td>-143.080082</td>\n",
       "      <td>33.019329</td>\n",
       "      <td>419.882279</td>\n",
       "      <td>31.396653</td>\n",
       "      <td>298.994012</td>\n",
       "      <td>734.331801</td>\n",
       "      <td>6.009446</td>\n",
       "      <td>336.570018</td>\n",
       "      <td>493.493772</td>\n",
       "      <td>...</td>\n",
       "      <td>-296.296557</td>\n",
       "      <td>171.977005</td>\n",
       "      <td>-98.391150</td>\n",
       "      <td>266.599380</td>\n",
       "      <td>218.419855</td>\n",
       "      <td>103.783066</td>\n",
       "      <td>173.819114</td>\n",
       "      <td>-46.882738</td>\n",
       "      <td>31.828383</td>\n",
       "      <td>15.123485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>396.114381</td>\n",
       "      <td>-204.779927</td>\n",
       "      <td>603.295619</td>\n",
       "      <td>313.186969</td>\n",
       "      <td>243.261952</td>\n",
       "      <td>209.929631</td>\n",
       "      <td>-11.560606</td>\n",
       "      <td>-169.665783</td>\n",
       "      <td>229.668188</td>\n",
       "      <td>534.347483</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.160653</td>\n",
       "      <td>97.843778</td>\n",
       "      <td>-46.070991</td>\n",
       "      <td>-25.387795</td>\n",
       "      <td>-123.505645</td>\n",
       "      <td>49.313490</td>\n",
       "      <td>-26.810581</td>\n",
       "      <td>61.877720</td>\n",
       "      <td>-13.118734</td>\n",
       "      <td>13.235290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-481.687153</td>\n",
       "      <td>437.056141</td>\n",
       "      <td>443.107931</td>\n",
       "      <td>-419.556936</td>\n",
       "      <td>-195.632284</td>\n",
       "      <td>141.190442</td>\n",
       "      <td>316.204750</td>\n",
       "      <td>80.118758</td>\n",
       "      <td>22.253059</td>\n",
       "      <td>-657.736106</td>\n",
       "      <td>...</td>\n",
       "      <td>3.687379</td>\n",
       "      <td>-15.413053</td>\n",
       "      <td>98.552400</td>\n",
       "      <td>139.104672</td>\n",
       "      <td>-104.877525</td>\n",
       "      <td>71.531087</td>\n",
       "      <td>-193.828963</td>\n",
       "      <td>99.039822</td>\n",
       "      <td>-151.238239</td>\n",
       "      <td>69.567780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>921.375125</td>\n",
       "      <td>989.206754</td>\n",
       "      <td>9.479557</td>\n",
       "      <td>936.945719</td>\n",
       "      <td>-127.384404</td>\n",
       "      <td>547.579313</td>\n",
       "      <td>-275.234426</td>\n",
       "      <td>295.043068</td>\n",
       "      <td>189.397806</td>\n",
       "      <td>292.743167</td>\n",
       "      <td>...</td>\n",
       "      <td>-241.491065</td>\n",
       "      <td>-124.806817</td>\n",
       "      <td>-147.969235</td>\n",
       "      <td>20.873952</td>\n",
       "      <td>-152.363708</td>\n",
       "      <td>-230.127989</td>\n",
       "      <td>44.185992</td>\n",
       "      <td>131.693277</td>\n",
       "      <td>92.660553</td>\n",
       "      <td>-125.615933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>67.030809</td>\n",
       "      <td>-67.193336</td>\n",
       "      <td>848.330454</td>\n",
       "      <td>-580.073727</td>\n",
       "      <td>175.636156</td>\n",
       "      <td>401.408282</td>\n",
       "      <td>-437.035752</td>\n",
       "      <td>-424.889642</td>\n",
       "      <td>266.230094</td>\n",
       "      <td>-170.148667</td>\n",
       "      <td>...</td>\n",
       "      <td>-198.456937</td>\n",
       "      <td>-53.343348</td>\n",
       "      <td>218.157087</td>\n",
       "      <td>-124.235128</td>\n",
       "      <td>-78.553890</td>\n",
       "      <td>23.050770</td>\n",
       "      <td>-71.003481</td>\n",
       "      <td>95.762023</td>\n",
       "      <td>97.364526</td>\n",
       "      <td>73.919020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>-693.147115</td>\n",
       "      <td>-658.707308</td>\n",
       "      <td>281.666888</td>\n",
       "      <td>162.770296</td>\n",
       "      <td>109.529720</td>\n",
       "      <td>609.949711</td>\n",
       "      <td>-673.401221</td>\n",
       "      <td>55.394084</td>\n",
       "      <td>351.856506</td>\n",
       "      <td>288.616655</td>\n",
       "      <td>...</td>\n",
       "      <td>220.959513</td>\n",
       "      <td>-102.947073</td>\n",
       "      <td>-5.820090</td>\n",
       "      <td>-170.145550</td>\n",
       "      <td>119.159529</td>\n",
       "      <td>130.727775</td>\n",
       "      <td>-2.772607</td>\n",
       "      <td>77.613373</td>\n",
       "      <td>-50.336005</td>\n",
       "      <td>-85.970958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>157.336130</td>\n",
       "      <td>272.452946</td>\n",
       "      <td>-396.912001</td>\n",
       "      <td>-487.263122</td>\n",
       "      <td>-335.341532</td>\n",
       "      <td>-205.080141</td>\n",
       "      <td>-219.069119</td>\n",
       "      <td>185.610826</td>\n",
       "      <td>-94.558243</td>\n",
       "      <td>-59.536021</td>\n",
       "      <td>...</td>\n",
       "      <td>-97.149173</td>\n",
       "      <td>62.250008</td>\n",
       "      <td>12.039001</td>\n",
       "      <td>3.413677</td>\n",
       "      <td>47.062362</td>\n",
       "      <td>47.642691</td>\n",
       "      <td>-146.830185</td>\n",
       "      <td>-423.798301</td>\n",
       "      <td>394.862328</td>\n",
       "      <td>33.388334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>502.265759</td>\n",
       "      <td>589.802190</td>\n",
       "      <td>-90.790383</td>\n",
       "      <td>968.254215</td>\n",
       "      <td>-346.484906</td>\n",
       "      <td>515.624305</td>\n",
       "      <td>-646.105869</td>\n",
       "      <td>-194.824749</td>\n",
       "      <td>603.456466</td>\n",
       "      <td>-376.568663</td>\n",
       "      <td>...</td>\n",
       "      <td>-103.865391</td>\n",
       "      <td>148.725828</td>\n",
       "      <td>-392.708699</td>\n",
       "      <td>229.367818</td>\n",
       "      <td>-52.250749</td>\n",
       "      <td>16.312360</td>\n",
       "      <td>34.704133</td>\n",
       "      <td>-0.429573</td>\n",
       "      <td>-1.302904</td>\n",
       "      <td>159.719306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0            1           2           3           4           5           6           7           8           9   ...          35          36          37          38          39          40          41          42          43          44\n",
       "0     -884.023692  -526.779091  128.919388  206.082051 -208.260172  504.770928 -352.482747  -76.854877  216.296789  -49.642854  ...    0.029621  -10.406068  145.718693   18.256846   54.591569  -13.047681   27.081955  -54.470397  -88.903501  170.139393\n",
       "1      257.098914  1027.080774 -411.141501 -401.603660  717.290205 -424.914873  114.042914 -211.447476   26.426887  357.251971  ...   69.894517   11.006854   18.747626  -80.959883    2.856614   57.195134   14.413934  -33.451316 -126.965686   25.051057\n",
       "2     -296.807408  -143.080082   33.019329  419.882279   31.396653  298.994012  734.331801    6.009446  336.570018  493.493772  ... -296.296557  171.977005  -98.391150  266.599380  218.419855  103.783066  173.819114  -46.882738   31.828383   15.123485\n",
       "3      396.114381  -204.779927  603.295619  313.186969  243.261952  209.929631  -11.560606 -169.665783  229.668188  534.347483  ...  -19.160653   97.843778  -46.070991  -25.387795 -123.505645   49.313490  -26.810581   61.877720  -13.118734   13.235290\n",
       "4     -481.687153   437.056141  443.107931 -419.556936 -195.632284  141.190442  316.204750   80.118758   22.253059 -657.736106  ...    3.687379  -15.413053   98.552400  139.104672 -104.877525   71.531087 -193.828963   99.039822 -151.238239   69.567780\n",
       "...           ...          ...         ...         ...         ...         ...         ...         ...         ...         ...  ...         ...         ...         ...         ...         ...         ...         ...         ...         ...         ...\n",
       "13995  921.375125   989.206754    9.479557  936.945719 -127.384404  547.579313 -275.234426  295.043068  189.397806  292.743167  ... -241.491065 -124.806817 -147.969235   20.873952 -152.363708 -230.127989   44.185992  131.693277   92.660553 -125.615933\n",
       "13996   67.030809   -67.193336  848.330454 -580.073727  175.636156  401.408282 -437.035752 -424.889642  266.230094 -170.148667  ... -198.456937  -53.343348  218.157087 -124.235128  -78.553890   23.050770  -71.003481   95.762023   97.364526   73.919020\n",
       "13997 -693.147115  -658.707308  281.666888  162.770296  109.529720  609.949711 -673.401221   55.394084  351.856506  288.616655  ...  220.959513 -102.947073   -5.820090 -170.145550  119.159529  130.727775   -2.772607   77.613373  -50.336005  -85.970958\n",
       "13998  157.336130   272.452946 -396.912001 -487.263122 -335.341532 -205.080141 -219.069119  185.610826  -94.558243  -59.536021  ...  -97.149173   62.250008   12.039001    3.413677   47.062362   47.642691 -146.830185 -423.798301  394.862328   33.388334\n",
       "13999  502.265759   589.802190  -90.790383  968.254215 -346.484906  515.624305 -646.105869 -194.824749  603.456466 -376.568663  ... -103.865391  148.725828 -392.708699  229.367818  -52.250749   16.312360   34.704133   -0.429573   -1.302904  159.719306\n",
       "\n",
       "[14000 rows x 45 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\liram\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# module loading\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# train data!\n",
    "rfc.fit(X_train_pca_mnist, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000,)\n"
     ]
    }
   ],
   "source": [
    "# make predicition\n",
    "prediction = rfc.predict(X_test_pca_mnist)\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1293,    0,    1,    3,    1,    1,    9,    1,    2,    1],\n",
       "       [   0, 1573,    9,    7,    2,    2,    2,    4,    5,    0],\n",
       "       [   6,    1, 1293,   11,    4,    2,    3,    9,   18,    1],\n",
       "       [   3,    4,   15, 1343,    2,   18,    2,    8,   23,    9],\n",
       "       [   1,    4,    5,    3, 1297,    3,   12,    6,    7,   24],\n",
       "       [   7,    0,    4,   28,    3, 1203,   11,    4,   16,    4],\n",
       "       [   4,    1,    3,    0,    3,   10, 1376,    0,    0,    0],\n",
       "       [   3,    2,   21,    3,   16,    2,    0, 1385,    3,   26],\n",
       "       [   2,    8,   14,   42,   11,   20,    5,    8, 1269,   11],\n",
       "       [   6,    4,    8,   27,   42,    6,    1,   28,    4, 1293]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:\n",
      "0.9517857142857142\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score:')\n",
    "print(metrics.accuracy_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.1976052\ttotal: 344ms\tremaining: 5m 44s\n",
      "1:\tlearn: 2.1106820\ttotal: 785ms\tremaining: 6m 31s\n",
      "2:\tlearn: 2.0327765\ttotal: 1.12s\tremaining: 6m 11s\n",
      "3:\tlearn: 1.9664756\ttotal: 1.57s\tremaining: 6m 29s\n",
      "4:\tlearn: 1.9075406\ttotal: 1.92s\tremaining: 6m 21s\n",
      "5:\tlearn: 1.8539156\ttotal: 2.19s\tremaining: 6m 3s\n",
      "6:\tlearn: 1.8051077\ttotal: 2.42s\tremaining: 5m 43s\n",
      "7:\tlearn: 1.7612135\ttotal: 2.64s\tremaining: 5m 27s\n",
      "8:\tlearn: 1.7192146\ttotal: 2.87s\tremaining: 5m 15s\n",
      "9:\tlearn: 1.6775705\ttotal: 3.09s\tremaining: 5m 6s\n",
      "10:\tlearn: 1.6411701\ttotal: 3.31s\tremaining: 4m 57s\n",
      "11:\tlearn: 1.6065097\ttotal: 3.53s\tremaining: 4m 50s\n",
      "12:\tlearn: 1.5744671\ttotal: 3.79s\tremaining: 4m 48s\n",
      "13:\tlearn: 1.5427355\ttotal: 4.05s\tremaining: 4m 45s\n",
      "14:\tlearn: 1.5143698\ttotal: 4.3s\tremaining: 4m 42s\n",
      "15:\tlearn: 1.4849556\ttotal: 4.62s\tremaining: 4m 44s\n",
      "16:\tlearn: 1.4582044\ttotal: 4.87s\tremaining: 4m 41s\n",
      "17:\tlearn: 1.4335783\ttotal: 5.1s\tremaining: 4m 38s\n",
      "18:\tlearn: 1.4094839\ttotal: 5.31s\tremaining: 4m 34s\n",
      "19:\tlearn: 1.3855734\ttotal: 5.53s\tremaining: 4m 30s\n",
      "20:\tlearn: 1.3601603\ttotal: 5.73s\tremaining: 4m 27s\n",
      "21:\tlearn: 1.3401193\ttotal: 5.95s\tremaining: 4m 24s\n",
      "22:\tlearn: 1.3200008\ttotal: 6.18s\tremaining: 4m 22s\n",
      "23:\tlearn: 1.3010888\ttotal: 6.39s\tremaining: 4m 19s\n",
      "24:\tlearn: 1.2818577\ttotal: 6.62s\tremaining: 4m 18s\n",
      "25:\tlearn: 1.2630464\ttotal: 6.85s\tremaining: 4m 16s\n",
      "26:\tlearn: 1.2434491\ttotal: 7.07s\tremaining: 4m 14s\n",
      "27:\tlearn: 1.2258396\ttotal: 7.3s\tremaining: 4m 13s\n",
      "28:\tlearn: 1.2099242\ttotal: 7.7s\tremaining: 4m 17s\n",
      "29:\tlearn: 1.1947600\ttotal: 7.96s\tremaining: 4m 17s\n",
      "30:\tlearn: 1.1801530\ttotal: 8.17s\tremaining: 4m 15s\n",
      "31:\tlearn: 1.1645951\ttotal: 8.39s\tremaining: 4m 13s\n",
      "32:\tlearn: 1.1486102\ttotal: 8.63s\tremaining: 4m 12s\n",
      "33:\tlearn: 1.1342218\ttotal: 8.9s\tremaining: 4m 12s\n",
      "34:\tlearn: 1.1205763\ttotal: 9.13s\tremaining: 4m 11s\n",
      "35:\tlearn: 1.1070399\ttotal: 9.38s\tremaining: 4m 11s\n",
      "36:\tlearn: 1.0940961\ttotal: 9.62s\tremaining: 4m 10s\n",
      "37:\tlearn: 1.0829322\ttotal: 9.9s\tremaining: 4m 10s\n",
      "38:\tlearn: 1.0712776\ttotal: 10.1s\tremaining: 4m 9s\n",
      "39:\tlearn: 1.0598747\ttotal: 10.4s\tremaining: 4m 8s\n",
      "40:\tlearn: 1.0485021\ttotal: 10.6s\tremaining: 4m 7s\n",
      "41:\tlearn: 1.0383809\ttotal: 10.8s\tremaining: 4m 6s\n",
      "42:\tlearn: 1.0276283\ttotal: 11.1s\tremaining: 4m 6s\n",
      "43:\tlearn: 1.0172862\ttotal: 11.3s\tremaining: 4m 5s\n",
      "44:\tlearn: 1.0062943\ttotal: 11.6s\tremaining: 4m 5s\n",
      "45:\tlearn: 0.9963986\ttotal: 11.9s\tremaining: 4m 5s\n",
      "46:\tlearn: 0.9875815\ttotal: 12.1s\tremaining: 4m 5s\n",
      "47:\tlearn: 0.9789732\ttotal: 12.3s\tremaining: 4m 4s\n",
      "48:\tlearn: 0.9707370\ttotal: 12.6s\tremaining: 4m 4s\n",
      "49:\tlearn: 0.9605793\ttotal: 12.8s\tremaining: 4m 3s\n",
      "50:\tlearn: 0.9526115\ttotal: 13.1s\tremaining: 4m 3s\n",
      "51:\tlearn: 0.9439136\ttotal: 13.3s\tremaining: 4m 3s\n",
      "52:\tlearn: 0.9341769\ttotal: 13.6s\tremaining: 4m 2s\n",
      "53:\tlearn: 0.9244532\ttotal: 13.8s\tremaining: 4m 2s\n",
      "54:\tlearn: 0.9161264\ttotal: 14.1s\tremaining: 4m 1s\n",
      "55:\tlearn: 0.9058606\ttotal: 14.3s\tremaining: 4m 1s\n",
      "56:\tlearn: 0.8984943\ttotal: 14.6s\tremaining: 4m 1s\n",
      "57:\tlearn: 0.8904696\ttotal: 14.8s\tremaining: 4m\n",
      "58:\tlearn: 0.8815348\ttotal: 15s\tremaining: 3m 59s\n",
      "59:\tlearn: 0.8735895\ttotal: 15.3s\tremaining: 3m 59s\n",
      "60:\tlearn: 0.8671878\ttotal: 15.5s\tremaining: 3m 59s\n",
      "61:\tlearn: 0.8603343\ttotal: 15.8s\tremaining: 3m 58s\n",
      "62:\tlearn: 0.8527339\ttotal: 16s\tremaining: 3m 58s\n",
      "63:\tlearn: 0.8463636\ttotal: 16.3s\tremaining: 3m 58s\n",
      "64:\tlearn: 0.8390985\ttotal: 16.6s\tremaining: 3m 58s\n",
      "65:\tlearn: 0.8325057\ttotal: 16.8s\tremaining: 3m 57s\n",
      "66:\tlearn: 0.8257619\ttotal: 17s\tremaining: 3m 57s\n",
      "67:\tlearn: 0.8193676\ttotal: 17.3s\tremaining: 3m 57s\n",
      "68:\tlearn: 0.8137247\ttotal: 17.5s\tremaining: 3m 56s\n",
      "69:\tlearn: 0.8074665\ttotal: 17.8s\tremaining: 3m 56s\n",
      "70:\tlearn: 0.8014659\ttotal: 18s\tremaining: 3m 55s\n",
      "71:\tlearn: 0.7959402\ttotal: 18.3s\tremaining: 3m 55s\n",
      "72:\tlearn: 0.7919880\ttotal: 18.5s\tremaining: 3m 54s\n",
      "73:\tlearn: 0.7859288\ttotal: 18.7s\tremaining: 3m 54s\n",
      "74:\tlearn: 0.7802088\ttotal: 19s\tremaining: 3m 54s\n",
      "75:\tlearn: 0.7747499\ttotal: 19.2s\tremaining: 3m 53s\n",
      "76:\tlearn: 0.7692188\ttotal: 19.5s\tremaining: 3m 53s\n",
      "77:\tlearn: 0.7626891\ttotal: 19.7s\tremaining: 3m 53s\n",
      "78:\tlearn: 0.7581473\ttotal: 20s\tremaining: 3m 52s\n",
      "79:\tlearn: 0.7523217\ttotal: 20.2s\tremaining: 3m 52s\n",
      "80:\tlearn: 0.7468167\ttotal: 20.5s\tremaining: 3m 52s\n",
      "81:\tlearn: 0.7410405\ttotal: 20.7s\tremaining: 3m 52s\n",
      "82:\tlearn: 0.7343339\ttotal: 21s\tremaining: 3m 51s\n",
      "83:\tlearn: 0.7284968\ttotal: 21.2s\tremaining: 3m 51s\n",
      "84:\tlearn: 0.7234333\ttotal: 21.5s\tremaining: 3m 51s\n",
      "85:\tlearn: 0.7185638\ttotal: 21.7s\tremaining: 3m 50s\n",
      "86:\tlearn: 0.7129728\ttotal: 22s\tremaining: 3m 50s\n",
      "87:\tlearn: 0.7066196\ttotal: 22.2s\tremaining: 3m 50s\n",
      "88:\tlearn: 0.7024002\ttotal: 22.5s\tremaining: 3m 50s\n",
      "89:\tlearn: 0.6978582\ttotal: 22.7s\tremaining: 3m 49s\n",
      "90:\tlearn: 0.6931190\ttotal: 23s\tremaining: 3m 49s\n",
      "91:\tlearn: 0.6882705\ttotal: 23.2s\tremaining: 3m 49s\n",
      "92:\tlearn: 0.6836937\ttotal: 23.5s\tremaining: 3m 49s\n",
      "93:\tlearn: 0.6800494\ttotal: 23.7s\tremaining: 3m 48s\n",
      "94:\tlearn: 0.6765722\ttotal: 24s\tremaining: 3m 48s\n",
      "95:\tlearn: 0.6720662\ttotal: 24.2s\tremaining: 3m 48s\n",
      "96:\tlearn: 0.6676912\ttotal: 24.5s\tremaining: 3m 47s\n",
      "97:\tlearn: 0.6643622\ttotal: 24.7s\tremaining: 3m 47s\n",
      "98:\tlearn: 0.6610004\ttotal: 25s\tremaining: 3m 47s\n",
      "99:\tlearn: 0.6562979\ttotal: 25.2s\tremaining: 3m 46s\n",
      "100:\tlearn: 0.6523809\ttotal: 25.5s\tremaining: 3m 46s\n",
      "101:\tlearn: 0.6481209\ttotal: 25.7s\tremaining: 3m 46s\n",
      "102:\tlearn: 0.6444702\ttotal: 26s\tremaining: 3m 46s\n",
      "103:\tlearn: 0.6409334\ttotal: 26.2s\tremaining: 3m 45s\n",
      "104:\tlearn: 0.6369354\ttotal: 26.4s\tremaining: 3m 45s\n",
      "105:\tlearn: 0.6326626\ttotal: 26.7s\tremaining: 3m 45s\n",
      "106:\tlearn: 0.6294654\ttotal: 26.9s\tremaining: 3m 44s\n",
      "107:\tlearn: 0.6260067\ttotal: 27.1s\tremaining: 3m 44s\n",
      "108:\tlearn: 0.6226453\ttotal: 27.4s\tremaining: 3m 43s\n",
      "109:\tlearn: 0.6195530\ttotal: 27.6s\tremaining: 3m 43s\n",
      "110:\tlearn: 0.6157857\ttotal: 27.9s\tremaining: 3m 43s\n",
      "111:\tlearn: 0.6116057\ttotal: 28.1s\tremaining: 3m 42s\n",
      "112:\tlearn: 0.6083526\ttotal: 28.4s\tremaining: 3m 42s\n",
      "113:\tlearn: 0.6047645\ttotal: 28.6s\tremaining: 3m 42s\n",
      "114:\tlearn: 0.6014029\ttotal: 28.9s\tremaining: 3m 42s\n",
      "115:\tlearn: 0.5987845\ttotal: 29.1s\tremaining: 3m 42s\n",
      "116:\tlearn: 0.5945711\ttotal: 29.4s\tremaining: 3m 41s\n",
      "117:\tlearn: 0.5910668\ttotal: 29.6s\tremaining: 3m 41s\n",
      "118:\tlearn: 0.5875015\ttotal: 29.9s\tremaining: 3m 41s\n",
      "119:\tlearn: 0.5837488\ttotal: 30.2s\tremaining: 3m 41s\n",
      "120:\tlearn: 0.5803202\ttotal: 30.4s\tremaining: 3m 41s\n",
      "121:\tlearn: 0.5775893\ttotal: 30.7s\tremaining: 3m 40s\n",
      "122:\tlearn: 0.5740805\ttotal: 30.9s\tremaining: 3m 40s\n",
      "123:\tlearn: 0.5714835\ttotal: 31.2s\tremaining: 3m 40s\n",
      "124:\tlearn: 0.5677314\ttotal: 31.5s\tremaining: 3m 40s\n",
      "125:\tlearn: 0.5650069\ttotal: 31.8s\tremaining: 3m 40s\n",
      "126:\tlearn: 0.5619935\ttotal: 32s\tremaining: 3m 40s\n",
      "127:\tlearn: 0.5590314\ttotal: 32.3s\tremaining: 3m 39s\n",
      "128:\tlearn: 0.5563630\ttotal: 32.6s\tremaining: 3m 39s\n",
      "129:\tlearn: 0.5533443\ttotal: 32.8s\tremaining: 3m 39s\n",
      "130:\tlearn: 0.5508213\ttotal: 33.1s\tremaining: 3m 39s\n",
      "131:\tlearn: 0.5483598\ttotal: 33.4s\tremaining: 3m 39s\n",
      "132:\tlearn: 0.5455358\ttotal: 33.7s\tremaining: 3m 39s\n",
      "133:\tlearn: 0.5429669\ttotal: 33.9s\tremaining: 3m 39s\n",
      "134:\tlearn: 0.5397292\ttotal: 34.2s\tremaining: 3m 39s\n",
      "135:\tlearn: 0.5369332\ttotal: 34.5s\tremaining: 3m 39s\n",
      "136:\tlearn: 0.5346549\ttotal: 34.8s\tremaining: 3m 39s\n",
      "137:\tlearn: 0.5320196\ttotal: 35.1s\tremaining: 3m 38s\n",
      "138:\tlearn: 0.5295896\ttotal: 35.4s\tremaining: 3m 38s\n",
      "139:\tlearn: 0.5271650\ttotal: 35.6s\tremaining: 3m 38s\n",
      "140:\tlearn: 0.5247846\ttotal: 35.9s\tremaining: 3m 38s\n",
      "141:\tlearn: 0.5220483\ttotal: 36.1s\tremaining: 3m 38s\n",
      "142:\tlearn: 0.5196550\ttotal: 36.4s\tremaining: 3m 37s\n",
      "143:\tlearn: 0.5174786\ttotal: 36.6s\tremaining: 3m 37s\n",
      "144:\tlearn: 0.5151469\ttotal: 36.9s\tremaining: 3m 37s\n",
      "145:\tlearn: 0.5128216\ttotal: 37.1s\tremaining: 3m 37s\n",
      "146:\tlearn: 0.5103792\ttotal: 37.4s\tremaining: 3m 36s\n",
      "147:\tlearn: 0.5072662\ttotal: 37.6s\tremaining: 3m 36s\n",
      "148:\tlearn: 0.5053902\ttotal: 37.9s\tremaining: 3m 36s\n",
      "149:\tlearn: 0.5033628\ttotal: 38.1s\tremaining: 3m 36s\n",
      "150:\tlearn: 0.5010642\ttotal: 38.4s\tremaining: 3m 35s\n",
      "151:\tlearn: 0.4987215\ttotal: 38.7s\tremaining: 3m 35s\n",
      "152:\tlearn: 0.4966918\ttotal: 38.9s\tremaining: 3m 35s\n",
      "153:\tlearn: 0.4947474\ttotal: 39.2s\tremaining: 3m 35s\n",
      "154:\tlearn: 0.4927250\ttotal: 39.4s\tremaining: 3m 34s\n",
      "155:\tlearn: 0.4910502\ttotal: 39.7s\tremaining: 3m 34s\n",
      "156:\tlearn: 0.4887737\ttotal: 39.9s\tremaining: 3m 34s\n",
      "157:\tlearn: 0.4866993\ttotal: 40.1s\tremaining: 3m 33s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158:\tlearn: 0.4846053\ttotal: 40.4s\tremaining: 3m 33s\n",
      "159:\tlearn: 0.4824949\ttotal: 40.6s\tremaining: 3m 33s\n",
      "160:\tlearn: 0.4801826\ttotal: 40.9s\tremaining: 3m 32s\n",
      "161:\tlearn: 0.4778413\ttotal: 41.1s\tremaining: 3m 32s\n",
      "162:\tlearn: 0.4760241\ttotal: 41.4s\tremaining: 3m 32s\n",
      "163:\tlearn: 0.4745097\ttotal: 41.6s\tremaining: 3m 32s\n",
      "164:\tlearn: 0.4721993\ttotal: 41.9s\tremaining: 3m 31s\n",
      "165:\tlearn: 0.4706815\ttotal: 42.1s\tremaining: 3m 31s\n",
      "166:\tlearn: 0.4688740\ttotal: 42.4s\tremaining: 3m 31s\n",
      "167:\tlearn: 0.4664966\ttotal: 42.7s\tremaining: 3m 31s\n",
      "168:\tlearn: 0.4643467\ttotal: 42.9s\tremaining: 3m 31s\n",
      "169:\tlearn: 0.4623305\ttotal: 43.2s\tremaining: 3m 30s\n",
      "170:\tlearn: 0.4607397\ttotal: 43.4s\tremaining: 3m 30s\n",
      "171:\tlearn: 0.4589058\ttotal: 43.7s\tremaining: 3m 30s\n",
      "172:\tlearn: 0.4570453\ttotal: 43.9s\tremaining: 3m 30s\n",
      "173:\tlearn: 0.4553922\ttotal: 44.2s\tremaining: 3m 29s\n",
      "174:\tlearn: 0.4538891\ttotal: 44.4s\tremaining: 3m 29s\n",
      "175:\tlearn: 0.4521694\ttotal: 44.7s\tremaining: 3m 29s\n",
      "176:\tlearn: 0.4504240\ttotal: 45s\tremaining: 3m 29s\n",
      "177:\tlearn: 0.4484802\ttotal: 45.2s\tremaining: 3m 28s\n",
      "178:\tlearn: 0.4467462\ttotal: 45.5s\tremaining: 3m 28s\n",
      "179:\tlearn: 0.4451164\ttotal: 45.7s\tremaining: 3m 28s\n",
      "180:\tlearn: 0.4432890\ttotal: 46s\tremaining: 3m 28s\n",
      "181:\tlearn: 0.4413753\ttotal: 46.3s\tremaining: 3m 27s\n",
      "182:\tlearn: 0.4398171\ttotal: 46.5s\tremaining: 3m 27s\n",
      "183:\tlearn: 0.4381070\ttotal: 46.8s\tremaining: 3m 27s\n",
      "184:\tlearn: 0.4366007\ttotal: 47s\tremaining: 3m 27s\n",
      "185:\tlearn: 0.4348073\ttotal: 47.3s\tremaining: 3m 26s\n",
      "186:\tlearn: 0.4330275\ttotal: 47.5s\tremaining: 3m 26s\n",
      "187:\tlearn: 0.4316444\ttotal: 47.7s\tremaining: 3m 25s\n",
      "188:\tlearn: 0.4300076\ttotal: 47.9s\tremaining: 3m 25s\n",
      "189:\tlearn: 0.4281210\ttotal: 48.1s\tremaining: 3m 25s\n",
      "190:\tlearn: 0.4266754\ttotal: 48.4s\tremaining: 3m 24s\n",
      "191:\tlearn: 0.4246910\ttotal: 48.6s\tremaining: 3m 24s\n",
      "192:\tlearn: 0.4232565\ttotal: 48.8s\tremaining: 3m 24s\n",
      "193:\tlearn: 0.4217003\ttotal: 49s\tremaining: 3m 23s\n",
      "194:\tlearn: 0.4204305\ttotal: 49.3s\tremaining: 3m 23s\n",
      "195:\tlearn: 0.4185155\ttotal: 49.5s\tremaining: 3m 23s\n",
      "196:\tlearn: 0.4170123\ttotal: 49.7s\tremaining: 3m 22s\n",
      "197:\tlearn: 0.4152741\ttotal: 50s\tremaining: 3m 22s\n",
      "198:\tlearn: 0.4137853\ttotal: 50.2s\tremaining: 3m 22s\n",
      "199:\tlearn: 0.4124205\ttotal: 50.5s\tremaining: 3m 21s\n",
      "200:\tlearn: 0.4106413\ttotal: 50.7s\tremaining: 3m 21s\n",
      "201:\tlearn: 0.4090255\ttotal: 50.9s\tremaining: 3m 21s\n",
      "202:\tlearn: 0.4076245\ttotal: 51.2s\tremaining: 3m 20s\n",
      "203:\tlearn: 0.4060123\ttotal: 51.4s\tremaining: 3m 20s\n",
      "204:\tlearn: 0.4046439\ttotal: 51.7s\tremaining: 3m 20s\n",
      "205:\tlearn: 0.4035874\ttotal: 51.9s\tremaining: 3m 20s\n",
      "206:\tlearn: 0.4018752\ttotal: 52.1s\tremaining: 3m 19s\n",
      "207:\tlearn: 0.4005191\ttotal: 52.4s\tremaining: 3m 19s\n",
      "208:\tlearn: 0.3989003\ttotal: 52.6s\tremaining: 3m 18s\n",
      "209:\tlearn: 0.3978408\ttotal: 52.8s\tremaining: 3m 18s\n",
      "210:\tlearn: 0.3965122\ttotal: 53s\tremaining: 3m 18s\n",
      "211:\tlearn: 0.3949622\ttotal: 53.2s\tremaining: 3m 17s\n",
      "212:\tlearn: 0.3932263\ttotal: 53.4s\tremaining: 3m 17s\n",
      "213:\tlearn: 0.3921254\ttotal: 53.6s\tremaining: 3m 16s\n",
      "214:\tlearn: 0.3909501\ttotal: 53.8s\tremaining: 3m 16s\n",
      "215:\tlearn: 0.3893794\ttotal: 54s\tremaining: 3m 15s\n",
      "216:\tlearn: 0.3884167\ttotal: 54.2s\tremaining: 3m 15s\n",
      "217:\tlearn: 0.3869822\ttotal: 54.4s\tremaining: 3m 15s\n",
      "218:\tlearn: 0.3858291\ttotal: 54.6s\tremaining: 3m 14s\n",
      "219:\tlearn: 0.3844709\ttotal: 54.9s\tremaining: 3m 14s\n",
      "220:\tlearn: 0.3833493\ttotal: 55.1s\tremaining: 3m 14s\n",
      "221:\tlearn: 0.3821202\ttotal: 55.3s\tremaining: 3m 13s\n",
      "222:\tlearn: 0.3808501\ttotal: 55.5s\tremaining: 3m 13s\n",
      "223:\tlearn: 0.3793798\ttotal: 55.8s\tremaining: 3m 13s\n",
      "224:\tlearn: 0.3782187\ttotal: 56s\tremaining: 3m 12s\n",
      "225:\tlearn: 0.3772302\ttotal: 56.2s\tremaining: 3m 12s\n",
      "226:\tlearn: 0.3762174\ttotal: 56.5s\tremaining: 3m 12s\n",
      "227:\tlearn: 0.3749955\ttotal: 56.7s\tremaining: 3m 12s\n",
      "228:\tlearn: 0.3738624\ttotal: 57s\tremaining: 3m 11s\n",
      "229:\tlearn: 0.3728625\ttotal: 57.2s\tremaining: 3m 11s\n",
      "230:\tlearn: 0.3718051\ttotal: 57.4s\tremaining: 3m 11s\n",
      "231:\tlearn: 0.3704108\ttotal: 57.7s\tremaining: 3m 11s\n",
      "232:\tlearn: 0.3695156\ttotal: 58s\tremaining: 3m 10s\n",
      "233:\tlearn: 0.3683567\ttotal: 58.2s\tremaining: 3m 10s\n",
      "234:\tlearn: 0.3673825\ttotal: 58.5s\tremaining: 3m 10s\n",
      "235:\tlearn: 0.3662408\ttotal: 58.6s\tremaining: 3m 9s\n",
      "236:\tlearn: 0.3650516\ttotal: 58.8s\tremaining: 3m 9s\n",
      "237:\tlearn: 0.3635883\ttotal: 59.1s\tremaining: 3m 9s\n",
      "238:\tlearn: 0.3625403\ttotal: 59.3s\tremaining: 3m 8s\n",
      "239:\tlearn: 0.3612671\ttotal: 59.6s\tremaining: 3m 8s\n",
      "240:\tlearn: 0.3599531\ttotal: 59.8s\tremaining: 3m 8s\n",
      "241:\tlearn: 0.3587694\ttotal: 1m\tremaining: 3m 8s\n",
      "242:\tlearn: 0.3576039\ttotal: 1m\tremaining: 3m 7s\n",
      "243:\tlearn: 0.3567167\ttotal: 1m\tremaining: 3m 7s\n",
      "244:\tlearn: 0.3557899\ttotal: 1m\tremaining: 3m 7s\n",
      "245:\tlearn: 0.3547839\ttotal: 1m 1s\tremaining: 3m 7s\n",
      "246:\tlearn: 0.3538896\ttotal: 1m 1s\tremaining: 3m 6s\n",
      "247:\tlearn: 0.3527794\ttotal: 1m 1s\tremaining: 3m 6s\n",
      "248:\tlearn: 0.3518225\ttotal: 1m 1s\tremaining: 3m 6s\n",
      "249:\tlearn: 0.3507651\ttotal: 1m 2s\tremaining: 3m 6s\n",
      "250:\tlearn: 0.3498415\ttotal: 1m 2s\tremaining: 3m 5s\n",
      "251:\tlearn: 0.3487759\ttotal: 1m 2s\tremaining: 3m 5s\n",
      "252:\tlearn: 0.3476244\ttotal: 1m 2s\tremaining: 3m 5s\n",
      "253:\tlearn: 0.3467746\ttotal: 1m 2s\tremaining: 3m 4s\n",
      "254:\tlearn: 0.3459578\ttotal: 1m 3s\tremaining: 3m 4s\n",
      "255:\tlearn: 0.3451152\ttotal: 1m 3s\tremaining: 3m 4s\n",
      "256:\tlearn: 0.3439617\ttotal: 1m 3s\tremaining: 3m 4s\n",
      "257:\tlearn: 0.3427816\ttotal: 1m 3s\tremaining: 3m 3s\n",
      "258:\tlearn: 0.3417074\ttotal: 1m 4s\tremaining: 3m 3s\n",
      "259:\tlearn: 0.3409365\ttotal: 1m 4s\tremaining: 3m 3s\n",
      "260:\tlearn: 0.3398590\ttotal: 1m 4s\tremaining: 3m 3s\n",
      "261:\tlearn: 0.3388866\ttotal: 1m 4s\tremaining: 3m 3s\n",
      "262:\tlearn: 0.3378796\ttotal: 1m 5s\tremaining: 3m 2s\n",
      "263:\tlearn: 0.3366196\ttotal: 1m 5s\tremaining: 3m 2s\n",
      "264:\tlearn: 0.3357262\ttotal: 1m 5s\tremaining: 3m 2s\n",
      "265:\tlearn: 0.3348948\ttotal: 1m 5s\tremaining: 3m 1s\n",
      "266:\tlearn: 0.3340399\ttotal: 1m 6s\tremaining: 3m 1s\n",
      "267:\tlearn: 0.3332669\ttotal: 1m 6s\tremaining: 3m 1s\n",
      "268:\tlearn: 0.3324249\ttotal: 1m 6s\tremaining: 3m 1s\n",
      "269:\tlearn: 0.3317125\ttotal: 1m 6s\tremaining: 3m\n",
      "270:\tlearn: 0.3309769\ttotal: 1m 7s\tremaining: 3m\n",
      "271:\tlearn: 0.3300568\ttotal: 1m 7s\tremaining: 2m 59s\n",
      "272:\tlearn: 0.3293181\ttotal: 1m 7s\tremaining: 2m 59s\n",
      "273:\tlearn: 0.3284116\ttotal: 1m 7s\tremaining: 2m 59s\n",
      "274:\tlearn: 0.3275773\ttotal: 1m 7s\tremaining: 2m 58s\n",
      "275:\tlearn: 0.3265860\ttotal: 1m 8s\tremaining: 2m 58s\n",
      "276:\tlearn: 0.3255162\ttotal: 1m 8s\tremaining: 2m 58s\n",
      "277:\tlearn: 0.3246572\ttotal: 1m 8s\tremaining: 2m 58s\n",
      "278:\tlearn: 0.3238560\ttotal: 1m 8s\tremaining: 2m 57s\n",
      "279:\tlearn: 0.3227646\ttotal: 1m 9s\tremaining: 2m 57s\n",
      "280:\tlearn: 0.3218782\ttotal: 1m 9s\tremaining: 2m 57s\n",
      "281:\tlearn: 0.3211672\ttotal: 1m 9s\tremaining: 2m 57s\n",
      "282:\tlearn: 0.3201758\ttotal: 1m 9s\tremaining: 2m 57s\n",
      "283:\tlearn: 0.3193625\ttotal: 1m 10s\tremaining: 2m 56s\n",
      "284:\tlearn: 0.3185890\ttotal: 1m 10s\tremaining: 2m 56s\n",
      "285:\tlearn: 0.3175368\ttotal: 1m 10s\tremaining: 2m 56s\n",
      "286:\tlearn: 0.3170689\ttotal: 1m 11s\tremaining: 2m 56s\n",
      "287:\tlearn: 0.3160865\ttotal: 1m 11s\tremaining: 2m 56s\n",
      "288:\tlearn: 0.3154558\ttotal: 1m 11s\tremaining: 2m 56s\n",
      "289:\tlearn: 0.3146053\ttotal: 1m 11s\tremaining: 2m 55s\n",
      "290:\tlearn: 0.3137466\ttotal: 1m 12s\tremaining: 2m 55s\n",
      "291:\tlearn: 0.3131074\ttotal: 1m 12s\tremaining: 2m 55s\n",
      "292:\tlearn: 0.3124792\ttotal: 1m 12s\tremaining: 2m 54s\n",
      "293:\tlearn: 0.3115665\ttotal: 1m 12s\tremaining: 2m 54s\n",
      "294:\tlearn: 0.3108771\ttotal: 1m 12s\tremaining: 2m 54s\n",
      "295:\tlearn: 0.3101904\ttotal: 1m 13s\tremaining: 2m 54s\n",
      "296:\tlearn: 0.3093629\ttotal: 1m 13s\tremaining: 2m 53s\n",
      "297:\tlearn: 0.3085952\ttotal: 1m 13s\tremaining: 2m 53s\n",
      "298:\tlearn: 0.3077506\ttotal: 1m 13s\tremaining: 2m 53s\n",
      "299:\tlearn: 0.3070703\ttotal: 1m 14s\tremaining: 2m 53s\n",
      "300:\tlearn: 0.3061748\ttotal: 1m 14s\tremaining: 2m 52s\n",
      "301:\tlearn: 0.3052581\ttotal: 1m 14s\tremaining: 2m 52s\n",
      "302:\tlearn: 0.3045507\ttotal: 1m 14s\tremaining: 2m 52s\n",
      "303:\tlearn: 0.3038386\ttotal: 1m 15s\tremaining: 2m 52s\n",
      "304:\tlearn: 0.3032401\ttotal: 1m 15s\tremaining: 2m 51s\n",
      "305:\tlearn: 0.3024744\ttotal: 1m 15s\tremaining: 2m 51s\n",
      "306:\tlearn: 0.3015395\ttotal: 1m 15s\tremaining: 2m 51s\n",
      "307:\tlearn: 0.3008367\ttotal: 1m 16s\tremaining: 2m 51s\n",
      "308:\tlearn: 0.3003112\ttotal: 1m 16s\tremaining: 2m 50s\n",
      "309:\tlearn: 0.2997721\ttotal: 1m 16s\tremaining: 2m 50s\n",
      "310:\tlearn: 0.2991792\ttotal: 1m 16s\tremaining: 2m 50s\n",
      "311:\tlearn: 0.2985252\ttotal: 1m 17s\tremaining: 2m 50s\n",
      "312:\tlearn: 0.2980038\ttotal: 1m 17s\tremaining: 2m 49s\n",
      "313:\tlearn: 0.2973848\ttotal: 1m 17s\tremaining: 2m 49s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314:\tlearn: 0.2965973\ttotal: 1m 17s\tremaining: 2m 49s\n",
      "315:\tlearn: 0.2958555\ttotal: 1m 18s\tremaining: 2m 48s\n",
      "316:\tlearn: 0.2951411\ttotal: 1m 18s\tremaining: 2m 48s\n",
      "317:\tlearn: 0.2944246\ttotal: 1m 18s\tremaining: 2m 48s\n",
      "318:\tlearn: 0.2936821\ttotal: 1m 18s\tremaining: 2m 48s\n",
      "319:\tlearn: 0.2930012\ttotal: 1m 19s\tremaining: 2m 47s\n",
      "320:\tlearn: 0.2924526\ttotal: 1m 19s\tremaining: 2m 47s\n",
      "321:\tlearn: 0.2916274\ttotal: 1m 19s\tremaining: 2m 47s\n",
      "322:\tlearn: 0.2909605\ttotal: 1m 19s\tremaining: 2m 46s\n",
      "323:\tlearn: 0.2903744\ttotal: 1m 19s\tremaining: 2m 46s\n",
      "324:\tlearn: 0.2896931\ttotal: 1m 20s\tremaining: 2m 46s\n",
      "325:\tlearn: 0.2890219\ttotal: 1m 20s\tremaining: 2m 45s\n",
      "326:\tlearn: 0.2882361\ttotal: 1m 20s\tremaining: 2m 45s\n",
      "327:\tlearn: 0.2875550\ttotal: 1m 20s\tremaining: 2m 45s\n",
      "328:\tlearn: 0.2866743\ttotal: 1m 20s\tremaining: 2m 45s\n",
      "329:\tlearn: 0.2860156\ttotal: 1m 21s\tremaining: 2m 45s\n",
      "330:\tlearn: 0.2854074\ttotal: 1m 21s\tremaining: 2m 44s\n",
      "331:\tlearn: 0.2848699\ttotal: 1m 21s\tremaining: 2m 44s\n",
      "332:\tlearn: 0.2843341\ttotal: 1m 22s\tremaining: 2m 44s\n",
      "333:\tlearn: 0.2837562\ttotal: 1m 22s\tremaining: 2m 43s\n",
      "334:\tlearn: 0.2832125\ttotal: 1m 22s\tremaining: 2m 43s\n",
      "335:\tlearn: 0.2828180\ttotal: 1m 22s\tremaining: 2m 43s\n",
      "336:\tlearn: 0.2821432\ttotal: 1m 22s\tremaining: 2m 43s\n",
      "337:\tlearn: 0.2814446\ttotal: 1m 23s\tremaining: 2m 42s\n",
      "338:\tlearn: 0.2809966\ttotal: 1m 23s\tremaining: 2m 42s\n",
      "339:\tlearn: 0.2804660\ttotal: 1m 23s\tremaining: 2m 42s\n",
      "340:\tlearn: 0.2800191\ttotal: 1m 23s\tremaining: 2m 42s\n",
      "341:\tlearn: 0.2794225\ttotal: 1m 24s\tremaining: 2m 41s\n",
      "342:\tlearn: 0.2787731\ttotal: 1m 24s\tremaining: 2m 41s\n",
      "343:\tlearn: 0.2781776\ttotal: 1m 24s\tremaining: 2m 41s\n",
      "344:\tlearn: 0.2776313\ttotal: 1m 24s\tremaining: 2m 40s\n",
      "345:\tlearn: 0.2769427\ttotal: 1m 25s\tremaining: 2m 40s\n",
      "346:\tlearn: 0.2764148\ttotal: 1m 25s\tremaining: 2m 40s\n",
      "347:\tlearn: 0.2757131\ttotal: 1m 25s\tremaining: 2m 40s\n",
      "348:\tlearn: 0.2753365\ttotal: 1m 25s\tremaining: 2m 39s\n",
      "349:\tlearn: 0.2747502\ttotal: 1m 25s\tremaining: 2m 39s\n",
      "350:\tlearn: 0.2742708\ttotal: 1m 26s\tremaining: 2m 39s\n",
      "351:\tlearn: 0.2737395\ttotal: 1m 26s\tremaining: 2m 39s\n",
      "352:\tlearn: 0.2733223\ttotal: 1m 26s\tremaining: 2m 38s\n",
      "353:\tlearn: 0.2727638\ttotal: 1m 26s\tremaining: 2m 38s\n",
      "354:\tlearn: 0.2722686\ttotal: 1m 27s\tremaining: 2m 38s\n",
      "355:\tlearn: 0.2718399\ttotal: 1m 27s\tremaining: 2m 38s\n",
      "356:\tlearn: 0.2710759\ttotal: 1m 27s\tremaining: 2m 37s\n",
      "357:\tlearn: 0.2706246\ttotal: 1m 27s\tremaining: 2m 37s\n",
      "358:\tlearn: 0.2702616\ttotal: 1m 28s\tremaining: 2m 37s\n",
      "359:\tlearn: 0.2695749\ttotal: 1m 28s\tremaining: 2m 37s\n",
      "360:\tlearn: 0.2692217\ttotal: 1m 28s\tremaining: 2m 36s\n",
      "361:\tlearn: 0.2687323\ttotal: 1m 28s\tremaining: 2m 36s\n",
      "362:\tlearn: 0.2682714\ttotal: 1m 29s\tremaining: 2m 36s\n",
      "363:\tlearn: 0.2676083\ttotal: 1m 29s\tremaining: 2m 35s\n",
      "364:\tlearn: 0.2668372\ttotal: 1m 29s\tremaining: 2m 35s\n",
      "365:\tlearn: 0.2662399\ttotal: 1m 29s\tremaining: 2m 35s\n",
      "366:\tlearn: 0.2657402\ttotal: 1m 29s\tremaining: 2m 35s\n",
      "367:\tlearn: 0.2652354\ttotal: 1m 30s\tremaining: 2m 34s\n",
      "368:\tlearn: 0.2646755\ttotal: 1m 30s\tremaining: 2m 34s\n",
      "369:\tlearn: 0.2640443\ttotal: 1m 30s\tremaining: 2m 34s\n",
      "370:\tlearn: 0.2635017\ttotal: 1m 30s\tremaining: 2m 34s\n",
      "371:\tlearn: 0.2630664\ttotal: 1m 31s\tremaining: 2m 33s\n",
      "372:\tlearn: 0.2625609\ttotal: 1m 31s\tremaining: 2m 33s\n",
      "373:\tlearn: 0.2619926\ttotal: 1m 31s\tremaining: 2m 33s\n",
      "374:\tlearn: 0.2616723\ttotal: 1m 31s\tremaining: 2m 33s\n",
      "375:\tlearn: 0.2612192\ttotal: 1m 32s\tremaining: 2m 32s\n",
      "376:\tlearn: 0.2605721\ttotal: 1m 32s\tremaining: 2m 32s\n",
      "377:\tlearn: 0.2600399\ttotal: 1m 32s\tremaining: 2m 32s\n",
      "378:\tlearn: 0.2594680\ttotal: 1m 32s\tremaining: 2m 32s\n",
      "379:\tlearn: 0.2591523\ttotal: 1m 33s\tremaining: 2m 31s\n",
      "380:\tlearn: 0.2586476\ttotal: 1m 33s\tremaining: 2m 31s\n",
      "381:\tlearn: 0.2581314\ttotal: 1m 33s\tremaining: 2m 31s\n",
      "382:\tlearn: 0.2576909\ttotal: 1m 33s\tremaining: 2m 31s\n",
      "383:\tlearn: 0.2571675\ttotal: 1m 34s\tremaining: 2m 30s\n",
      "384:\tlearn: 0.2567858\ttotal: 1m 34s\tremaining: 2m 30s\n",
      "385:\tlearn: 0.2563427\ttotal: 1m 34s\tremaining: 2m 30s\n",
      "386:\tlearn: 0.2557501\ttotal: 1m 34s\tremaining: 2m 30s\n",
      "387:\tlearn: 0.2552078\ttotal: 1m 35s\tremaining: 2m 29s\n",
      "388:\tlearn: 0.2544401\ttotal: 1m 35s\tremaining: 2m 29s\n",
      "389:\tlearn: 0.2539484\ttotal: 1m 35s\tremaining: 2m 29s\n",
      "390:\tlearn: 0.2536496\ttotal: 1m 35s\tremaining: 2m 29s\n",
      "391:\tlearn: 0.2530935\ttotal: 1m 36s\tremaining: 2m 29s\n",
      "392:\tlearn: 0.2527974\ttotal: 1m 36s\tremaining: 2m 28s\n",
      "393:\tlearn: 0.2523809\ttotal: 1m 36s\tremaining: 2m 28s\n",
      "394:\tlearn: 0.2520532\ttotal: 1m 36s\tremaining: 2m 28s\n",
      "395:\tlearn: 0.2515949\ttotal: 1m 37s\tremaining: 2m 28s\n",
      "396:\tlearn: 0.2510430\ttotal: 1m 37s\tremaining: 2m 28s\n",
      "397:\tlearn: 0.2506549\ttotal: 1m 37s\tremaining: 2m 27s\n",
      "398:\tlearn: 0.2500195\ttotal: 1m 37s\tremaining: 2m 27s\n",
      "399:\tlearn: 0.2497371\ttotal: 1m 38s\tremaining: 2m 27s\n",
      "400:\tlearn: 0.2493978\ttotal: 1m 38s\tremaining: 2m 27s\n",
      "401:\tlearn: 0.2491401\ttotal: 1m 38s\tremaining: 2m 26s\n",
      "402:\tlearn: 0.2487285\ttotal: 1m 38s\tremaining: 2m 26s\n",
      "403:\tlearn: 0.2484010\ttotal: 1m 39s\tremaining: 2m 26s\n",
      "404:\tlearn: 0.2478880\ttotal: 1m 39s\tremaining: 2m 26s\n",
      "405:\tlearn: 0.2474974\ttotal: 1m 39s\tremaining: 2m 25s\n",
      "406:\tlearn: 0.2471142\ttotal: 1m 39s\tremaining: 2m 25s\n",
      "407:\tlearn: 0.2467972\ttotal: 1m 40s\tremaining: 2m 25s\n",
      "408:\tlearn: 0.2465407\ttotal: 1m 40s\tremaining: 2m 25s\n",
      "409:\tlearn: 0.2461345\ttotal: 1m 40s\tremaining: 2m 24s\n",
      "410:\tlearn: 0.2457999\ttotal: 1m 40s\tremaining: 2m 24s\n",
      "411:\tlearn: 0.2452115\ttotal: 1m 41s\tremaining: 2m 24s\n",
      "412:\tlearn: 0.2445899\ttotal: 1m 41s\tremaining: 2m 23s\n",
      "413:\tlearn: 0.2442719\ttotal: 1m 41s\tremaining: 2m 23s\n",
      "414:\tlearn: 0.2438604\ttotal: 1m 41s\tremaining: 2m 23s\n",
      "415:\tlearn: 0.2432715\ttotal: 1m 42s\tremaining: 2m 23s\n",
      "416:\tlearn: 0.2429259\ttotal: 1m 42s\tremaining: 2m 22s\n",
      "417:\tlearn: 0.2425909\ttotal: 1m 42s\tremaining: 2m 22s\n",
      "418:\tlearn: 0.2422706\ttotal: 1m 42s\tremaining: 2m 22s\n",
      "419:\tlearn: 0.2418625\ttotal: 1m 42s\tremaining: 2m 22s\n",
      "420:\tlearn: 0.2416547\ttotal: 1m 43s\tremaining: 2m 21s\n",
      "421:\tlearn: 0.2412935\ttotal: 1m 43s\tremaining: 2m 21s\n",
      "422:\tlearn: 0.2410101\ttotal: 1m 43s\tremaining: 2m 21s\n",
      "423:\tlearn: 0.2406756\ttotal: 1m 43s\tremaining: 2m 21s\n",
      "424:\tlearn: 0.2401474\ttotal: 1m 44s\tremaining: 2m 20s\n",
      "425:\tlearn: 0.2396929\ttotal: 1m 44s\tremaining: 2m 20s\n",
      "426:\tlearn: 0.2391545\ttotal: 1m 44s\tremaining: 2m 20s\n",
      "427:\tlearn: 0.2388162\ttotal: 1m 44s\tremaining: 2m 19s\n",
      "428:\tlearn: 0.2383202\ttotal: 1m 44s\tremaining: 2m 19s\n",
      "429:\tlearn: 0.2378405\ttotal: 1m 45s\tremaining: 2m 19s\n",
      "430:\tlearn: 0.2375309\ttotal: 1m 45s\tremaining: 2m 19s\n",
      "431:\tlearn: 0.2372077\ttotal: 1m 45s\tremaining: 2m 18s\n",
      "432:\tlearn: 0.2367195\ttotal: 1m 45s\tremaining: 2m 18s\n",
      "433:\tlearn: 0.2363482\ttotal: 1m 46s\tremaining: 2m 18s\n",
      "434:\tlearn: 0.2360087\ttotal: 1m 46s\tremaining: 2m 18s\n",
      "435:\tlearn: 0.2357271\ttotal: 1m 46s\tremaining: 2m 17s\n",
      "436:\tlearn: 0.2353575\ttotal: 1m 46s\tremaining: 2m 17s\n",
      "437:\tlearn: 0.2351123\ttotal: 1m 46s\tremaining: 2m 17s\n",
      "438:\tlearn: 0.2347721\ttotal: 1m 47s\tremaining: 2m 16s\n",
      "439:\tlearn: 0.2344029\ttotal: 1m 47s\tremaining: 2m 16s\n",
      "440:\tlearn: 0.2342168\ttotal: 1m 47s\tremaining: 2m 16s\n",
      "441:\tlearn: 0.2337195\ttotal: 1m 47s\tremaining: 2m 16s\n",
      "442:\tlearn: 0.2333055\ttotal: 1m 48s\tremaining: 2m 15s\n",
      "443:\tlearn: 0.2329441\ttotal: 1m 48s\tremaining: 2m 15s\n",
      "444:\tlearn: 0.2327569\ttotal: 1m 48s\tremaining: 2m 15s\n",
      "445:\tlearn: 0.2323961\ttotal: 1m 48s\tremaining: 2m 15s\n",
      "446:\tlearn: 0.2320357\ttotal: 1m 48s\tremaining: 2m 14s\n",
      "447:\tlearn: 0.2316340\ttotal: 1m 49s\tremaining: 2m 14s\n",
      "448:\tlearn: 0.2312380\ttotal: 1m 49s\tremaining: 2m 14s\n",
      "449:\tlearn: 0.2309249\ttotal: 1m 49s\tremaining: 2m 13s\n",
      "450:\tlearn: 0.2305493\ttotal: 1m 49s\tremaining: 2m 13s\n",
      "451:\tlearn: 0.2300823\ttotal: 1m 50s\tremaining: 2m 13s\n",
      "452:\tlearn: 0.2295062\ttotal: 1m 50s\tremaining: 2m 13s\n",
      "453:\tlearn: 0.2291951\ttotal: 1m 50s\tremaining: 2m 12s\n",
      "454:\tlearn: 0.2288335\ttotal: 1m 50s\tremaining: 2m 12s\n",
      "455:\tlearn: 0.2284213\ttotal: 1m 51s\tremaining: 2m 12s\n",
      "456:\tlearn: 0.2280615\ttotal: 1m 51s\tremaining: 2m 12s\n",
      "457:\tlearn: 0.2276492\ttotal: 1m 51s\tremaining: 2m 11s\n",
      "458:\tlearn: 0.2273002\ttotal: 1m 51s\tremaining: 2m 11s\n",
      "459:\tlearn: 0.2270410\ttotal: 1m 51s\tremaining: 2m 11s\n",
      "460:\tlearn: 0.2268213\ttotal: 1m 52s\tremaining: 2m 11s\n",
      "461:\tlearn: 0.2264053\ttotal: 1m 52s\tremaining: 2m 10s\n",
      "462:\tlearn: 0.2261025\ttotal: 1m 52s\tremaining: 2m 10s\n",
      "463:\tlearn: 0.2257649\ttotal: 1m 52s\tremaining: 2m 10s\n",
      "464:\tlearn: 0.2255159\ttotal: 1m 53s\tremaining: 2m 10s\n",
      "465:\tlearn: 0.2252929\ttotal: 1m 53s\tremaining: 2m 9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466:\tlearn: 0.2250698\ttotal: 1m 53s\tremaining: 2m 9s\n",
      "467:\tlearn: 0.2247401\ttotal: 1m 53s\tremaining: 2m 9s\n",
      "468:\tlearn: 0.2242705\ttotal: 1m 54s\tremaining: 2m 9s\n",
      "469:\tlearn: 0.2239149\ttotal: 1m 54s\tremaining: 2m 8s\n",
      "470:\tlearn: 0.2236352\ttotal: 1m 54s\tremaining: 2m 8s\n",
      "471:\tlearn: 0.2233875\ttotal: 1m 54s\tremaining: 2m 8s\n",
      "472:\tlearn: 0.2228446\ttotal: 1m 54s\tremaining: 2m 8s\n",
      "473:\tlearn: 0.2225372\ttotal: 1m 55s\tremaining: 2m 7s\n",
      "474:\tlearn: 0.2222569\ttotal: 1m 55s\tremaining: 2m 7s\n",
      "475:\tlearn: 0.2220238\ttotal: 1m 55s\tremaining: 2m 7s\n",
      "476:\tlearn: 0.2216968\ttotal: 1m 55s\tremaining: 2m 7s\n",
      "477:\tlearn: 0.2213782\ttotal: 1m 56s\tremaining: 2m 6s\n",
      "478:\tlearn: 0.2210985\ttotal: 1m 56s\tremaining: 2m 6s\n",
      "479:\tlearn: 0.2207760\ttotal: 1m 56s\tremaining: 2m 6s\n",
      "480:\tlearn: 0.2206148\ttotal: 1m 56s\tremaining: 2m 6s\n",
      "481:\tlearn: 0.2204429\ttotal: 1m 57s\tremaining: 2m 5s\n",
      "482:\tlearn: 0.2201455\ttotal: 1m 57s\tremaining: 2m 5s\n",
      "483:\tlearn: 0.2198842\ttotal: 1m 57s\tremaining: 2m 5s\n",
      "484:\tlearn: 0.2195581\ttotal: 1m 57s\tremaining: 2m 5s\n",
      "485:\tlearn: 0.2192623\ttotal: 1m 57s\tremaining: 2m 4s\n",
      "486:\tlearn: 0.2191229\ttotal: 1m 58s\tremaining: 2m 4s\n",
      "487:\tlearn: 0.2188345\ttotal: 1m 58s\tremaining: 2m 4s\n",
      "488:\tlearn: 0.2185581\ttotal: 1m 58s\tremaining: 2m 3s\n",
      "489:\tlearn: 0.2181983\ttotal: 1m 58s\tremaining: 2m 3s\n",
      "490:\tlearn: 0.2177495\ttotal: 1m 59s\tremaining: 2m 3s\n",
      "491:\tlearn: 0.2174913\ttotal: 1m 59s\tremaining: 2m 3s\n",
      "492:\tlearn: 0.2172219\ttotal: 1m 59s\tremaining: 2m 2s\n",
      "493:\tlearn: 0.2170129\ttotal: 1m 59s\tremaining: 2m 2s\n",
      "494:\tlearn: 0.2168023\ttotal: 1m 59s\tremaining: 2m 2s\n",
      "495:\tlearn: 0.2165483\ttotal: 2m\tremaining: 2m 2s\n",
      "496:\tlearn: 0.2163550\ttotal: 2m\tremaining: 2m 1s\n",
      "497:\tlearn: 0.2160782\ttotal: 2m\tremaining: 2m 1s\n",
      "498:\tlearn: 0.2157921\ttotal: 2m\tremaining: 2m 1s\n",
      "499:\tlearn: 0.2156493\ttotal: 2m 1s\tremaining: 2m 1s\n",
      "500:\tlearn: 0.2153887\ttotal: 2m 1s\tremaining: 2m\n",
      "501:\tlearn: 0.2150680\ttotal: 2m 1s\tremaining: 2m\n",
      "502:\tlearn: 0.2148789\ttotal: 2m 1s\tremaining: 2m\n",
      "503:\tlearn: 0.2145969\ttotal: 2m 1s\tremaining: 1m 59s\n",
      "504:\tlearn: 0.2142753\ttotal: 2m 2s\tremaining: 1m 59s\n",
      "505:\tlearn: 0.2139572\ttotal: 2m 2s\tremaining: 1m 59s\n",
      "506:\tlearn: 0.2137018\ttotal: 2m 2s\tremaining: 1m 59s\n",
      "507:\tlearn: 0.2134543\ttotal: 2m 2s\tremaining: 1m 58s\n",
      "508:\tlearn: 0.2130835\ttotal: 2m 2s\tremaining: 1m 58s\n",
      "509:\tlearn: 0.2128234\ttotal: 2m 3s\tremaining: 1m 58s\n",
      "510:\tlearn: 0.2126345\ttotal: 2m 3s\tremaining: 1m 58s\n",
      "511:\tlearn: 0.2124435\ttotal: 2m 3s\tremaining: 1m 57s\n",
      "512:\tlearn: 0.2122637\ttotal: 2m 3s\tremaining: 1m 57s\n",
      "513:\tlearn: 0.2120005\ttotal: 2m 4s\tremaining: 1m 57s\n",
      "514:\tlearn: 0.2117563\ttotal: 2m 4s\tremaining: 1m 57s\n",
      "515:\tlearn: 0.2113924\ttotal: 2m 4s\tremaining: 1m 56s\n",
      "516:\tlearn: 0.2112256\ttotal: 2m 4s\tremaining: 1m 56s\n",
      "517:\tlearn: 0.2109817\ttotal: 2m 4s\tremaining: 1m 56s\n",
      "518:\tlearn: 0.2106595\ttotal: 2m 5s\tremaining: 1m 55s\n",
      "519:\tlearn: 0.2103377\ttotal: 2m 5s\tremaining: 1m 55s\n",
      "520:\tlearn: 0.2101286\ttotal: 2m 5s\tremaining: 1m 55s\n",
      "521:\tlearn: 0.2096785\ttotal: 2m 5s\tremaining: 1m 55s\n",
      "522:\tlearn: 0.2094350\ttotal: 2m 6s\tremaining: 1m 54s\n",
      "523:\tlearn: 0.2091035\ttotal: 2m 6s\tremaining: 1m 54s\n",
      "524:\tlearn: 0.2087660\ttotal: 2m 6s\tremaining: 1m 54s\n",
      "525:\tlearn: 0.2084597\ttotal: 2m 6s\tremaining: 1m 54s\n",
      "526:\tlearn: 0.2080428\ttotal: 2m 6s\tremaining: 1m 53s\n",
      "527:\tlearn: 0.2077648\ttotal: 2m 7s\tremaining: 1m 53s\n",
      "528:\tlearn: 0.2075287\ttotal: 2m 7s\tremaining: 1m 53s\n",
      "529:\tlearn: 0.2072586\ttotal: 2m 7s\tremaining: 1m 53s\n",
      "530:\tlearn: 0.2070038\ttotal: 2m 7s\tremaining: 1m 52s\n",
      "531:\tlearn: 0.2067214\ttotal: 2m 7s\tremaining: 1m 52s\n",
      "532:\tlearn: 0.2065316\ttotal: 2m 8s\tremaining: 1m 52s\n",
      "533:\tlearn: 0.2062062\ttotal: 2m 8s\tremaining: 1m 52s\n",
      "534:\tlearn: 0.2057630\ttotal: 2m 8s\tremaining: 1m 51s\n",
      "535:\tlearn: 0.2054229\ttotal: 2m 8s\tremaining: 1m 51s\n",
      "536:\tlearn: 0.2050113\ttotal: 2m 9s\tremaining: 1m 51s\n",
      "537:\tlearn: 0.2046571\ttotal: 2m 9s\tremaining: 1m 51s\n",
      "538:\tlearn: 0.2043572\ttotal: 2m 9s\tremaining: 1m 50s\n",
      "539:\tlearn: 0.2040173\ttotal: 2m 9s\tremaining: 1m 50s\n",
      "540:\tlearn: 0.2037619\ttotal: 2m 10s\tremaining: 1m 50s\n",
      "541:\tlearn: 0.2035828\ttotal: 2m 10s\tremaining: 1m 50s\n",
      "542:\tlearn: 0.2034223\ttotal: 2m 10s\tremaining: 1m 49s\n",
      "543:\tlearn: 0.2031624\ttotal: 2m 10s\tremaining: 1m 49s\n",
      "544:\tlearn: 0.2028485\ttotal: 2m 10s\tremaining: 1m 49s\n",
      "545:\tlearn: 0.2023925\ttotal: 2m 11s\tremaining: 1m 49s\n",
      "546:\tlearn: 0.2022303\ttotal: 2m 11s\tremaining: 1m 48s\n",
      "547:\tlearn: 0.2020568\ttotal: 2m 11s\tremaining: 1m 48s\n",
      "548:\tlearn: 0.2018322\ttotal: 2m 11s\tremaining: 1m 48s\n",
      "549:\tlearn: 0.2016182\ttotal: 2m 12s\tremaining: 1m 48s\n",
      "550:\tlearn: 0.2014421\ttotal: 2m 12s\tremaining: 1m 47s\n",
      "551:\tlearn: 0.2012473\ttotal: 2m 12s\tremaining: 1m 47s\n",
      "552:\tlearn: 0.2009151\ttotal: 2m 12s\tremaining: 1m 47s\n",
      "553:\tlearn: 0.2006910\ttotal: 2m 13s\tremaining: 1m 47s\n",
      "554:\tlearn: 0.2004184\ttotal: 2m 13s\tremaining: 1m 46s\n",
      "555:\tlearn: 0.2001769\ttotal: 2m 13s\tremaining: 1m 46s\n",
      "556:\tlearn: 0.1998832\ttotal: 2m 13s\tremaining: 1m 46s\n",
      "557:\tlearn: 0.1997578\ttotal: 2m 13s\tremaining: 1m 46s\n",
      "558:\tlearn: 0.1995151\ttotal: 2m 14s\tremaining: 1m 45s\n",
      "559:\tlearn: 0.1992766\ttotal: 2m 14s\tremaining: 1m 45s\n",
      "560:\tlearn: 0.1991377\ttotal: 2m 14s\tremaining: 1m 45s\n",
      "561:\tlearn: 0.1989875\ttotal: 2m 14s\tremaining: 1m 45s\n",
      "562:\tlearn: 0.1988482\ttotal: 2m 15s\tremaining: 1m 44s\n",
      "563:\tlearn: 0.1985972\ttotal: 2m 15s\tremaining: 1m 44s\n",
      "564:\tlearn: 0.1983509\ttotal: 2m 15s\tremaining: 1m 44s\n",
      "565:\tlearn: 0.1981063\ttotal: 2m 15s\tremaining: 1m 44s\n",
      "566:\tlearn: 0.1978132\ttotal: 2m 15s\tremaining: 1m 43s\n",
      "567:\tlearn: 0.1975967\ttotal: 2m 16s\tremaining: 1m 43s\n",
      "568:\tlearn: 0.1973784\ttotal: 2m 16s\tremaining: 1m 43s\n",
      "569:\tlearn: 0.1971691\ttotal: 2m 16s\tremaining: 1m 43s\n",
      "570:\tlearn: 0.1970130\ttotal: 2m 16s\tremaining: 1m 42s\n",
      "571:\tlearn: 0.1967434\ttotal: 2m 17s\tremaining: 1m 42s\n",
      "572:\tlearn: 0.1965757\ttotal: 2m 17s\tremaining: 1m 42s\n",
      "573:\tlearn: 0.1963116\ttotal: 2m 17s\tremaining: 1m 42s\n",
      "574:\tlearn: 0.1961006\ttotal: 2m 17s\tremaining: 1m 41s\n",
      "575:\tlearn: 0.1959870\ttotal: 2m 17s\tremaining: 1m 41s\n",
      "576:\tlearn: 0.1956439\ttotal: 2m 18s\tremaining: 1m 41s\n",
      "577:\tlearn: 0.1955042\ttotal: 2m 18s\tremaining: 1m 41s\n",
      "578:\tlearn: 0.1953251\ttotal: 2m 18s\tremaining: 1m 40s\n",
      "579:\tlearn: 0.1951572\ttotal: 2m 18s\tremaining: 1m 40s\n",
      "580:\tlearn: 0.1949302\ttotal: 2m 19s\tremaining: 1m 40s\n",
      "581:\tlearn: 0.1946944\ttotal: 2m 19s\tremaining: 1m 40s\n",
      "582:\tlearn: 0.1944816\ttotal: 2m 19s\tremaining: 1m 39s\n",
      "583:\tlearn: 0.1943048\ttotal: 2m 19s\tremaining: 1m 39s\n",
      "584:\tlearn: 0.1941512\ttotal: 2m 19s\tremaining: 1m 39s\n",
      "585:\tlearn: 0.1939719\ttotal: 2m 20s\tremaining: 1m 39s\n",
      "586:\tlearn: 0.1936541\ttotal: 2m 20s\tremaining: 1m 38s\n",
      "587:\tlearn: 0.1931601\ttotal: 2m 20s\tremaining: 1m 38s\n",
      "588:\tlearn: 0.1928184\ttotal: 2m 20s\tremaining: 1m 38s\n",
      "589:\tlearn: 0.1926458\ttotal: 2m 21s\tremaining: 1m 38s\n",
      "590:\tlearn: 0.1924923\ttotal: 2m 21s\tremaining: 1m 37s\n",
      "591:\tlearn: 0.1923237\ttotal: 2m 21s\tremaining: 1m 37s\n",
      "592:\tlearn: 0.1919301\ttotal: 2m 21s\tremaining: 1m 37s\n",
      "593:\tlearn: 0.1916291\ttotal: 2m 21s\tremaining: 1m 37s\n",
      "594:\tlearn: 0.1913193\ttotal: 2m 22s\tremaining: 1m 36s\n",
      "595:\tlearn: 0.1910881\ttotal: 2m 22s\tremaining: 1m 36s\n",
      "596:\tlearn: 0.1909231\ttotal: 2m 22s\tremaining: 1m 36s\n",
      "597:\tlearn: 0.1907647\ttotal: 2m 22s\tremaining: 1m 36s\n",
      "598:\tlearn: 0.1905896\ttotal: 2m 23s\tremaining: 1m 35s\n",
      "599:\tlearn: 0.1902762\ttotal: 2m 23s\tremaining: 1m 35s\n",
      "600:\tlearn: 0.1900448\ttotal: 2m 23s\tremaining: 1m 35s\n",
      "601:\tlearn: 0.1898510\ttotal: 2m 23s\tremaining: 1m 35s\n",
      "602:\tlearn: 0.1896728\ttotal: 2m 24s\tremaining: 1m 34s\n",
      "603:\tlearn: 0.1894495\ttotal: 2m 24s\tremaining: 1m 34s\n",
      "604:\tlearn: 0.1892429\ttotal: 2m 24s\tremaining: 1m 34s\n",
      "605:\tlearn: 0.1890173\ttotal: 2m 24s\tremaining: 1m 34s\n",
      "606:\tlearn: 0.1887988\ttotal: 2m 24s\tremaining: 1m 33s\n",
      "607:\tlearn: 0.1885890\ttotal: 2m 25s\tremaining: 1m 33s\n",
      "608:\tlearn: 0.1884021\ttotal: 2m 25s\tremaining: 1m 33s\n",
      "609:\tlearn: 0.1882286\ttotal: 2m 25s\tremaining: 1m 33s\n",
      "610:\tlearn: 0.1880878\ttotal: 2m 25s\tremaining: 1m 32s\n",
      "611:\tlearn: 0.1877604\ttotal: 2m 26s\tremaining: 1m 32s\n",
      "612:\tlearn: 0.1874628\ttotal: 2m 26s\tremaining: 1m 32s\n",
      "613:\tlearn: 0.1872699\ttotal: 2m 26s\tremaining: 1m 32s\n",
      "614:\tlearn: 0.1870727\ttotal: 2m 26s\tremaining: 1m 31s\n",
      "615:\tlearn: 0.1869752\ttotal: 2m 26s\tremaining: 1m 31s\n",
      "616:\tlearn: 0.1867558\ttotal: 2m 27s\tremaining: 1m 31s\n",
      "617:\tlearn: 0.1865297\ttotal: 2m 27s\tremaining: 1m 31s\n",
      "618:\tlearn: 0.1863808\ttotal: 2m 27s\tremaining: 1m 30s\n",
      "619:\tlearn: 0.1862225\ttotal: 2m 27s\tremaining: 1m 30s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620:\tlearn: 0.1860441\ttotal: 2m 28s\tremaining: 1m 30s\n",
      "621:\tlearn: 0.1859431\ttotal: 2m 28s\tremaining: 1m 30s\n",
      "622:\tlearn: 0.1856161\ttotal: 2m 28s\tremaining: 1m 29s\n",
      "623:\tlearn: 0.1854589\ttotal: 2m 28s\tremaining: 1m 29s\n",
      "624:\tlearn: 0.1853127\ttotal: 2m 29s\tremaining: 1m 29s\n",
      "625:\tlearn: 0.1851621\ttotal: 2m 29s\tremaining: 1m 29s\n",
      "626:\tlearn: 0.1850163\ttotal: 2m 29s\tremaining: 1m 28s\n",
      "627:\tlearn: 0.1848733\ttotal: 2m 29s\tremaining: 1m 28s\n",
      "628:\tlearn: 0.1846076\ttotal: 2m 30s\tremaining: 1m 28s\n",
      "629:\tlearn: 0.1845102\ttotal: 2m 30s\tremaining: 1m 28s\n",
      "630:\tlearn: 0.1843416\ttotal: 2m 30s\tremaining: 1m 28s\n",
      "631:\tlearn: 0.1842907\ttotal: 2m 30s\tremaining: 1m 27s\n",
      "632:\tlearn: 0.1842016\ttotal: 2m 31s\tremaining: 1m 27s\n",
      "633:\tlearn: 0.1840431\ttotal: 2m 31s\tremaining: 1m 27s\n",
      "634:\tlearn: 0.1838286\ttotal: 2m 31s\tremaining: 1m 27s\n",
      "635:\tlearn: 0.1837278\ttotal: 2m 31s\tremaining: 1m 26s\n",
      "636:\tlearn: 0.1833499\ttotal: 2m 32s\tremaining: 1m 26s\n",
      "637:\tlearn: 0.1832093\ttotal: 2m 32s\tremaining: 1m 26s\n",
      "638:\tlearn: 0.1828282\ttotal: 2m 32s\tremaining: 1m 26s\n",
      "639:\tlearn: 0.1826625\ttotal: 2m 32s\tremaining: 1m 26s\n",
      "640:\tlearn: 0.1824951\ttotal: 2m 33s\tremaining: 1m 25s\n",
      "641:\tlearn: 0.1823110\ttotal: 2m 33s\tremaining: 1m 25s\n",
      "642:\tlearn: 0.1821742\ttotal: 2m 33s\tremaining: 1m 25s\n",
      "643:\tlearn: 0.1820638\ttotal: 2m 33s\tremaining: 1m 25s\n",
      "644:\tlearn: 0.1820039\ttotal: 2m 34s\tremaining: 1m 24s\n",
      "645:\tlearn: 0.1817829\ttotal: 2m 34s\tremaining: 1m 24s\n",
      "646:\tlearn: 0.1816785\ttotal: 2m 34s\tremaining: 1m 24s\n",
      "647:\tlearn: 0.1815319\ttotal: 2m 34s\tremaining: 1m 24s\n",
      "648:\tlearn: 0.1814001\ttotal: 2m 35s\tremaining: 1m 23s\n",
      "649:\tlearn: 0.1812251\ttotal: 2m 35s\tremaining: 1m 23s\n",
      "650:\tlearn: 0.1811110\ttotal: 2m 35s\tremaining: 1m 23s\n",
      "651:\tlearn: 0.1809976\ttotal: 2m 35s\tremaining: 1m 23s\n",
      "652:\tlearn: 0.1808889\ttotal: 2m 36s\tremaining: 1m 22s\n",
      "653:\tlearn: 0.1807734\ttotal: 2m 36s\tremaining: 1m 22s\n",
      "654:\tlearn: 0.1806555\ttotal: 2m 36s\tremaining: 1m 22s\n",
      "655:\tlearn: 0.1805071\ttotal: 2m 36s\tremaining: 1m 22s\n",
      "656:\tlearn: 0.1802914\ttotal: 2m 37s\tremaining: 1m 22s\n",
      "657:\tlearn: 0.1801977\ttotal: 2m 37s\tremaining: 1m 21s\n",
      "658:\tlearn: 0.1800817\ttotal: 2m 37s\tremaining: 1m 21s\n",
      "659:\tlearn: 0.1799131\ttotal: 2m 37s\tremaining: 1m 21s\n",
      "660:\tlearn: 0.1797808\ttotal: 2m 38s\tremaining: 1m 21s\n",
      "661:\tlearn: 0.1796678\ttotal: 2m 38s\tremaining: 1m 20s\n",
      "662:\tlearn: 0.1795046\ttotal: 2m 38s\tremaining: 1m 20s\n",
      "663:\tlearn: 0.1792887\ttotal: 2m 38s\tremaining: 1m 20s\n",
      "664:\tlearn: 0.1791660\ttotal: 2m 39s\tremaining: 1m 20s\n",
      "665:\tlearn: 0.1788475\ttotal: 2m 39s\tremaining: 1m 19s\n",
      "666:\tlearn: 0.1787081\ttotal: 2m 39s\tremaining: 1m 19s\n",
      "667:\tlearn: 0.1784503\ttotal: 2m 39s\tremaining: 1m 19s\n",
      "668:\tlearn: 0.1782113\ttotal: 2m 40s\tremaining: 1m 19s\n",
      "669:\tlearn: 0.1780209\ttotal: 2m 40s\tremaining: 1m 18s\n",
      "670:\tlearn: 0.1778532\ttotal: 2m 40s\tremaining: 1m 18s\n",
      "671:\tlearn: 0.1776540\ttotal: 2m 40s\tremaining: 1m 18s\n",
      "672:\tlearn: 0.1775277\ttotal: 2m 41s\tremaining: 1m 18s\n",
      "673:\tlearn: 0.1771524\ttotal: 2m 41s\tremaining: 1m 18s\n",
      "674:\tlearn: 0.1769331\ttotal: 2m 41s\tremaining: 1m 17s\n",
      "675:\tlearn: 0.1766751\ttotal: 2m 41s\tremaining: 1m 17s\n",
      "676:\tlearn: 0.1765160\ttotal: 2m 42s\tremaining: 1m 17s\n",
      "677:\tlearn: 0.1763193\ttotal: 2m 42s\tremaining: 1m 17s\n",
      "678:\tlearn: 0.1760742\ttotal: 2m 42s\tremaining: 1m 16s\n",
      "679:\tlearn: 0.1759525\ttotal: 2m 42s\tremaining: 1m 16s\n",
      "680:\tlearn: 0.1758295\ttotal: 2m 43s\tremaining: 1m 16s\n",
      "681:\tlearn: 0.1757173\ttotal: 2m 43s\tremaining: 1m 16s\n",
      "682:\tlearn: 0.1755620\ttotal: 2m 43s\tremaining: 1m 15s\n",
      "683:\tlearn: 0.1754034\ttotal: 2m 43s\tremaining: 1m 15s\n",
      "684:\tlearn: 0.1753088\ttotal: 2m 43s\tremaining: 1m 15s\n",
      "685:\tlearn: 0.1751716\ttotal: 2m 44s\tremaining: 1m 15s\n",
      "686:\tlearn: 0.1749682\ttotal: 2m 44s\tremaining: 1m 14s\n",
      "687:\tlearn: 0.1748764\ttotal: 2m 44s\tremaining: 1m 14s\n",
      "688:\tlearn: 0.1747569\ttotal: 2m 44s\tremaining: 1m 14s\n",
      "689:\tlearn: 0.1746467\ttotal: 2m 45s\tremaining: 1m 14s\n",
      "690:\tlearn: 0.1743894\ttotal: 2m 45s\tremaining: 1m 14s\n",
      "691:\tlearn: 0.1742824\ttotal: 2m 45s\tremaining: 1m 13s\n",
      "692:\tlearn: 0.1740943\ttotal: 2m 45s\tremaining: 1m 13s\n",
      "693:\tlearn: 0.1739556\ttotal: 2m 46s\tremaining: 1m 13s\n",
      "694:\tlearn: 0.1738311\ttotal: 2m 46s\tremaining: 1m 13s\n",
      "695:\tlearn: 0.1736597\ttotal: 2m 46s\tremaining: 1m 12s\n",
      "696:\tlearn: 0.1735171\ttotal: 2m 46s\tremaining: 1m 12s\n",
      "697:\tlearn: 0.1733493\ttotal: 2m 47s\tremaining: 1m 12s\n",
      "698:\tlearn: 0.1731912\ttotal: 2m 47s\tremaining: 1m 12s\n",
      "699:\tlearn: 0.1730434\ttotal: 2m 47s\tremaining: 1m 11s\n",
      "700:\tlearn: 0.1729371\ttotal: 2m 47s\tremaining: 1m 11s\n",
      "701:\tlearn: 0.1727109\ttotal: 2m 48s\tremaining: 1m 11s\n",
      "702:\tlearn: 0.1726189\ttotal: 2m 48s\tremaining: 1m 11s\n",
      "703:\tlearn: 0.1723937\ttotal: 2m 48s\tremaining: 1m 10s\n",
      "704:\tlearn: 0.1721676\ttotal: 2m 48s\tremaining: 1m 10s\n",
      "705:\tlearn: 0.1718948\ttotal: 2m 49s\tremaining: 1m 10s\n",
      "706:\tlearn: 0.1717914\ttotal: 2m 49s\tremaining: 1m 10s\n",
      "707:\tlearn: 0.1716776\ttotal: 2m 49s\tremaining: 1m 9s\n",
      "708:\tlearn: 0.1715055\ttotal: 2m 49s\tremaining: 1m 9s\n",
      "709:\tlearn: 0.1713875\ttotal: 2m 49s\tremaining: 1m 9s\n",
      "710:\tlearn: 0.1712824\ttotal: 2m 50s\tremaining: 1m 9s\n",
      "711:\tlearn: 0.1711317\ttotal: 2m 50s\tremaining: 1m 8s\n",
      "712:\tlearn: 0.1709841\ttotal: 2m 50s\tremaining: 1m 8s\n",
      "713:\tlearn: 0.1707931\ttotal: 2m 51s\tremaining: 1m 8s\n",
      "714:\tlearn: 0.1706221\ttotal: 2m 51s\tremaining: 1m 8s\n",
      "715:\tlearn: 0.1703909\ttotal: 2m 51s\tremaining: 1m 8s\n",
      "716:\tlearn: 0.1703017\ttotal: 2m 51s\tremaining: 1m 7s\n",
      "717:\tlearn: 0.1702223\ttotal: 2m 51s\tremaining: 1m 7s\n",
      "718:\tlearn: 0.1701032\ttotal: 2m 52s\tremaining: 1m 7s\n",
      "719:\tlearn: 0.1699399\ttotal: 2m 52s\tremaining: 1m 7s\n",
      "720:\tlearn: 0.1697503\ttotal: 2m 52s\tremaining: 1m 6s\n",
      "721:\tlearn: 0.1696513\ttotal: 2m 52s\tremaining: 1m 6s\n",
      "722:\tlearn: 0.1695286\ttotal: 2m 53s\tremaining: 1m 6s\n",
      "723:\tlearn: 0.1693227\ttotal: 2m 53s\tremaining: 1m 6s\n",
      "724:\tlearn: 0.1692302\ttotal: 2m 53s\tremaining: 1m 5s\n",
      "725:\tlearn: 0.1689255\ttotal: 2m 53s\tremaining: 1m 5s\n",
      "726:\tlearn: 0.1687313\ttotal: 2m 54s\tremaining: 1m 5s\n",
      "727:\tlearn: 0.1686386\ttotal: 2m 54s\tremaining: 1m 5s\n",
      "728:\tlearn: 0.1684941\ttotal: 2m 54s\tremaining: 1m 4s\n",
      "729:\tlearn: 0.1684157\ttotal: 2m 54s\tremaining: 1m 4s\n",
      "730:\tlearn: 0.1683472\ttotal: 2m 54s\tremaining: 1m 4s\n",
      "731:\tlearn: 0.1682123\ttotal: 2m 55s\tremaining: 1m 4s\n",
      "732:\tlearn: 0.1679656\ttotal: 2m 55s\tremaining: 1m 3s\n",
      "733:\tlearn: 0.1676689\ttotal: 2m 55s\tremaining: 1m 3s\n",
      "734:\tlearn: 0.1675362\ttotal: 2m 55s\tremaining: 1m 3s\n",
      "735:\tlearn: 0.1673991\ttotal: 2m 56s\tremaining: 1m 3s\n",
      "736:\tlearn: 0.1673263\ttotal: 2m 56s\tremaining: 1m 2s\n",
      "737:\tlearn: 0.1671931\ttotal: 2m 56s\tremaining: 1m 2s\n",
      "738:\tlearn: 0.1670590\ttotal: 2m 56s\tremaining: 1m 2s\n",
      "739:\tlearn: 0.1668032\ttotal: 2m 57s\tremaining: 1m 2s\n",
      "740:\tlearn: 0.1665838\ttotal: 2m 57s\tremaining: 1m 1s\n",
      "741:\tlearn: 0.1664931\ttotal: 2m 57s\tremaining: 1m 1s\n",
      "742:\tlearn: 0.1663980\ttotal: 2m 57s\tremaining: 1m 1s\n",
      "743:\tlearn: 0.1663034\ttotal: 2m 58s\tremaining: 1m 1s\n",
      "744:\tlearn: 0.1660640\ttotal: 2m 58s\tremaining: 1m 1s\n",
      "745:\tlearn: 0.1659328\ttotal: 2m 58s\tremaining: 1m\n",
      "746:\tlearn: 0.1658071\ttotal: 2m 58s\tremaining: 1m\n",
      "747:\tlearn: 0.1657116\ttotal: 2m 58s\tremaining: 1m\n",
      "748:\tlearn: 0.1656243\ttotal: 2m 59s\tremaining: 1m\n",
      "749:\tlearn: 0.1654614\ttotal: 2m 59s\tremaining: 59.8s\n",
      "750:\tlearn: 0.1653124\ttotal: 2m 59s\tremaining: 59.5s\n",
      "751:\tlearn: 0.1651399\ttotal: 2m 59s\tremaining: 59.3s\n",
      "752:\tlearn: 0.1648676\ttotal: 2m 59s\tremaining: 59s\n",
      "753:\tlearn: 0.1646935\ttotal: 3m\tremaining: 58.8s\n",
      "754:\tlearn: 0.1646078\ttotal: 3m\tremaining: 58.6s\n",
      "755:\tlearn: 0.1645062\ttotal: 3m\tremaining: 58.3s\n",
      "756:\tlearn: 0.1643447\ttotal: 3m\tremaining: 58.1s\n",
      "757:\tlearn: 0.1642287\ttotal: 3m 1s\tremaining: 57.8s\n",
      "758:\tlearn: 0.1640332\ttotal: 3m 1s\tremaining: 57.6s\n",
      "759:\tlearn: 0.1638898\ttotal: 3m 1s\tremaining: 57.3s\n",
      "760:\tlearn: 0.1638073\ttotal: 3m 1s\tremaining: 57.1s\n",
      "761:\tlearn: 0.1636731\ttotal: 3m 2s\tremaining: 56.9s\n",
      "762:\tlearn: 0.1636182\ttotal: 3m 2s\tremaining: 56.6s\n",
      "763:\tlearn: 0.1634753\ttotal: 3m 2s\tremaining: 56.4s\n",
      "764:\tlearn: 0.1633647\ttotal: 3m 2s\tremaining: 56.1s\n",
      "765:\tlearn: 0.1632873\ttotal: 3m 2s\tremaining: 55.9s\n",
      "766:\tlearn: 0.1631842\ttotal: 3m 3s\tremaining: 55.6s\n",
      "767:\tlearn: 0.1630695\ttotal: 3m 3s\tremaining: 55.4s\n",
      "768:\tlearn: 0.1629647\ttotal: 3m 3s\tremaining: 55.2s\n",
      "769:\tlearn: 0.1628072\ttotal: 3m 3s\tremaining: 54.9s\n",
      "770:\tlearn: 0.1626496\ttotal: 3m 4s\tremaining: 54.7s\n",
      "771:\tlearn: 0.1625388\ttotal: 3m 4s\tremaining: 54.4s\n",
      "772:\tlearn: 0.1623293\ttotal: 3m 4s\tremaining: 54.2s\n",
      "773:\tlearn: 0.1621043\ttotal: 3m 4s\tremaining: 53.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774:\tlearn: 0.1620373\ttotal: 3m 4s\tremaining: 53.7s\n",
      "775:\tlearn: 0.1619081\ttotal: 3m 5s\tremaining: 53.4s\n",
      "776:\tlearn: 0.1616238\ttotal: 3m 5s\tremaining: 53.2s\n",
      "777:\tlearn: 0.1614850\ttotal: 3m 5s\tremaining: 53s\n",
      "778:\tlearn: 0.1614177\ttotal: 3m 5s\tremaining: 52.7s\n",
      "779:\tlearn: 0.1613375\ttotal: 3m 6s\tremaining: 52.5s\n",
      "780:\tlearn: 0.1612471\ttotal: 3m 6s\tremaining: 52.2s\n",
      "781:\tlearn: 0.1611187\ttotal: 3m 6s\tremaining: 52s\n",
      "782:\tlearn: 0.1608946\ttotal: 3m 6s\tremaining: 51.7s\n",
      "783:\tlearn: 0.1608073\ttotal: 3m 6s\tremaining: 51.5s\n",
      "784:\tlearn: 0.1607196\ttotal: 3m 7s\tremaining: 51.3s\n",
      "785:\tlearn: 0.1605894\ttotal: 3m 7s\tremaining: 51s\n",
      "786:\tlearn: 0.1605066\ttotal: 3m 7s\tremaining: 50.8s\n",
      "787:\tlearn: 0.1604206\ttotal: 3m 7s\tremaining: 50.5s\n",
      "788:\tlearn: 0.1602407\ttotal: 3m 8s\tremaining: 50.3s\n",
      "789:\tlearn: 0.1600574\ttotal: 3m 8s\tremaining: 50.1s\n",
      "790:\tlearn: 0.1599566\ttotal: 3m 8s\tremaining: 49.8s\n",
      "791:\tlearn: 0.1598015\ttotal: 3m 8s\tremaining: 49.6s\n",
      "792:\tlearn: 0.1597059\ttotal: 3m 8s\tremaining: 49.3s\n",
      "793:\tlearn: 0.1596036\ttotal: 3m 9s\tremaining: 49.1s\n",
      "794:\tlearn: 0.1594541\ttotal: 3m 9s\tremaining: 48.8s\n",
      "795:\tlearn: 0.1593167\ttotal: 3m 9s\tremaining: 48.6s\n",
      "796:\tlearn: 0.1591880\ttotal: 3m 9s\tremaining: 48.4s\n",
      "797:\tlearn: 0.1590636\ttotal: 3m 10s\tremaining: 48.1s\n",
      "798:\tlearn: 0.1589336\ttotal: 3m 10s\tremaining: 47.9s\n",
      "799:\tlearn: 0.1588025\ttotal: 3m 10s\tremaining: 47.6s\n",
      "800:\tlearn: 0.1586064\ttotal: 3m 10s\tremaining: 47.4s\n",
      "801:\tlearn: 0.1584540\ttotal: 3m 11s\tremaining: 47.2s\n",
      "802:\tlearn: 0.1583425\ttotal: 3m 11s\tremaining: 46.9s\n",
      "803:\tlearn: 0.1582564\ttotal: 3m 11s\tremaining: 46.7s\n",
      "804:\tlearn: 0.1579534\ttotal: 3m 11s\tremaining: 46.4s\n",
      "805:\tlearn: 0.1578311\ttotal: 3m 11s\tremaining: 46.2s\n",
      "806:\tlearn: 0.1576691\ttotal: 3m 12s\tremaining: 46s\n",
      "807:\tlearn: 0.1575669\ttotal: 3m 12s\tremaining: 45.7s\n",
      "808:\tlearn: 0.1574267\ttotal: 3m 12s\tremaining: 45.5s\n",
      "809:\tlearn: 0.1573242\ttotal: 3m 12s\tremaining: 45.2s\n",
      "810:\tlearn: 0.1571793\ttotal: 3m 13s\tremaining: 45s\n",
      "811:\tlearn: 0.1570834\ttotal: 3m 13s\tremaining: 44.8s\n",
      "812:\tlearn: 0.1569510\ttotal: 3m 13s\tremaining: 44.5s\n",
      "813:\tlearn: 0.1568401\ttotal: 3m 13s\tremaining: 44.3s\n",
      "814:\tlearn: 0.1566689\ttotal: 3m 13s\tremaining: 44s\n",
      "815:\tlearn: 0.1565608\ttotal: 3m 14s\tremaining: 43.8s\n",
      "816:\tlearn: 0.1564408\ttotal: 3m 14s\tremaining: 43.5s\n",
      "817:\tlearn: 0.1561560\ttotal: 3m 14s\tremaining: 43.3s\n",
      "818:\tlearn: 0.1560378\ttotal: 3m 14s\tremaining: 43.1s\n",
      "819:\tlearn: 0.1559049\ttotal: 3m 15s\tremaining: 42.8s\n",
      "820:\tlearn: 0.1558000\ttotal: 3m 15s\tremaining: 42.6s\n",
      "821:\tlearn: 0.1556915\ttotal: 3m 15s\tremaining: 42.3s\n",
      "822:\tlearn: 0.1556219\ttotal: 3m 15s\tremaining: 42.1s\n",
      "823:\tlearn: 0.1555740\ttotal: 3m 15s\tremaining: 41.9s\n",
      "824:\tlearn: 0.1554819\ttotal: 3m 16s\tremaining: 41.6s\n",
      "825:\tlearn: 0.1554336\ttotal: 3m 16s\tremaining: 41.4s\n",
      "826:\tlearn: 0.1553310\ttotal: 3m 16s\tremaining: 41.1s\n",
      "827:\tlearn: 0.1551933\ttotal: 3m 16s\tremaining: 40.9s\n",
      "828:\tlearn: 0.1551306\ttotal: 3m 17s\tremaining: 40.7s\n",
      "829:\tlearn: 0.1549955\ttotal: 3m 17s\tremaining: 40.4s\n",
      "830:\tlearn: 0.1549527\ttotal: 3m 17s\tremaining: 40.2s\n",
      "831:\tlearn: 0.1548621\ttotal: 3m 17s\tremaining: 39.9s\n",
      "832:\tlearn: 0.1547619\ttotal: 3m 17s\tremaining: 39.7s\n",
      "833:\tlearn: 0.1546873\ttotal: 3m 18s\tremaining: 39.5s\n",
      "834:\tlearn: 0.1545934\ttotal: 3m 18s\tremaining: 39.2s\n",
      "835:\tlearn: 0.1545100\ttotal: 3m 18s\tremaining: 39s\n",
      "836:\tlearn: 0.1543843\ttotal: 3m 18s\tremaining: 38.7s\n",
      "837:\tlearn: 0.1543209\ttotal: 3m 19s\tremaining: 38.5s\n",
      "838:\tlearn: 0.1542273\ttotal: 3m 19s\tremaining: 38.3s\n",
      "839:\tlearn: 0.1541283\ttotal: 3m 19s\tremaining: 38s\n",
      "840:\tlearn: 0.1540399\ttotal: 3m 19s\tremaining: 37.8s\n",
      "841:\tlearn: 0.1539285\ttotal: 3m 20s\tremaining: 37.5s\n",
      "842:\tlearn: 0.1538377\ttotal: 3m 20s\tremaining: 37.3s\n",
      "843:\tlearn: 0.1536922\ttotal: 3m 20s\tremaining: 37.1s\n",
      "844:\tlearn: 0.1535637\ttotal: 3m 20s\tremaining: 36.8s\n",
      "845:\tlearn: 0.1534753\ttotal: 3m 20s\tremaining: 36.6s\n",
      "846:\tlearn: 0.1534011\ttotal: 3m 21s\tremaining: 36.3s\n",
      "847:\tlearn: 0.1532874\ttotal: 3m 21s\tremaining: 36.1s\n",
      "848:\tlearn: 0.1531508\ttotal: 3m 21s\tremaining: 35.9s\n",
      "849:\tlearn: 0.1529125\ttotal: 3m 21s\tremaining: 35.6s\n",
      "850:\tlearn: 0.1528145\ttotal: 3m 22s\tremaining: 35.4s\n",
      "851:\tlearn: 0.1527459\ttotal: 3m 22s\tremaining: 35.2s\n",
      "852:\tlearn: 0.1526642\ttotal: 3m 22s\tremaining: 34.9s\n",
      "853:\tlearn: 0.1525340\ttotal: 3m 22s\tremaining: 34.7s\n",
      "854:\tlearn: 0.1524241\ttotal: 3m 23s\tremaining: 34.4s\n",
      "855:\tlearn: 0.1523275\ttotal: 3m 23s\tremaining: 34.2s\n",
      "856:\tlearn: 0.1522546\ttotal: 3m 23s\tremaining: 33.9s\n",
      "857:\tlearn: 0.1521776\ttotal: 3m 23s\tremaining: 33.7s\n",
      "858:\tlearn: 0.1520267\ttotal: 3m 23s\tremaining: 33.5s\n",
      "859:\tlearn: 0.1519264\ttotal: 3m 24s\tremaining: 33.2s\n",
      "860:\tlearn: 0.1518012\ttotal: 3m 24s\tremaining: 33s\n",
      "861:\tlearn: 0.1516969\ttotal: 3m 24s\tremaining: 32.8s\n",
      "862:\tlearn: 0.1516043\ttotal: 3m 24s\tremaining: 32.5s\n",
      "863:\tlearn: 0.1514233\ttotal: 3m 25s\tremaining: 32.3s\n",
      "864:\tlearn: 0.1513314\ttotal: 3m 25s\tremaining: 32s\n",
      "865:\tlearn: 0.1511420\ttotal: 3m 25s\tremaining: 31.8s\n",
      "866:\tlearn: 0.1510716\ttotal: 3m 25s\tremaining: 31.6s\n",
      "867:\tlearn: 0.1510263\ttotal: 3m 26s\tremaining: 31.3s\n",
      "868:\tlearn: 0.1509154\ttotal: 3m 26s\tremaining: 31.1s\n",
      "869:\tlearn: 0.1508470\ttotal: 3m 26s\tremaining: 30.9s\n",
      "870:\tlearn: 0.1507617\ttotal: 3m 26s\tremaining: 30.6s\n",
      "871:\tlearn: 0.1506185\ttotal: 3m 26s\tremaining: 30.4s\n",
      "872:\tlearn: 0.1504290\ttotal: 3m 27s\tremaining: 30.1s\n",
      "873:\tlearn: 0.1502108\ttotal: 3m 27s\tremaining: 29.9s\n",
      "874:\tlearn: 0.1501091\ttotal: 3m 27s\tremaining: 29.7s\n",
      "875:\tlearn: 0.1500330\ttotal: 3m 27s\tremaining: 29.4s\n",
      "876:\tlearn: 0.1499034\ttotal: 3m 28s\tremaining: 29.2s\n",
      "877:\tlearn: 0.1497615\ttotal: 3m 28s\tremaining: 29s\n",
      "878:\tlearn: 0.1495955\ttotal: 3m 28s\tremaining: 28.7s\n",
      "879:\tlearn: 0.1495234\ttotal: 3m 28s\tremaining: 28.5s\n",
      "880:\tlearn: 0.1493787\ttotal: 3m 29s\tremaining: 28.2s\n",
      "881:\tlearn: 0.1492083\ttotal: 3m 29s\tremaining: 28s\n",
      "882:\tlearn: 0.1491386\ttotal: 3m 29s\tremaining: 27.8s\n",
      "883:\tlearn: 0.1489991\ttotal: 3m 29s\tremaining: 27.5s\n",
      "884:\tlearn: 0.1489081\ttotal: 3m 30s\tremaining: 27.3s\n",
      "885:\tlearn: 0.1486959\ttotal: 3m 30s\tremaining: 27.1s\n",
      "886:\tlearn: 0.1486353\ttotal: 3m 30s\tremaining: 26.8s\n",
      "887:\tlearn: 0.1485457\ttotal: 3m 30s\tremaining: 26.6s\n",
      "888:\tlearn: 0.1484649\ttotal: 3m 31s\tremaining: 26.4s\n",
      "889:\tlearn: 0.1483942\ttotal: 3m 31s\tremaining: 26.1s\n",
      "890:\tlearn: 0.1482424\ttotal: 3m 31s\tremaining: 25.9s\n",
      "891:\tlearn: 0.1481343\ttotal: 3m 31s\tremaining: 25.6s\n",
      "892:\tlearn: 0.1480157\ttotal: 3m 32s\tremaining: 25.4s\n",
      "893:\tlearn: 0.1479156\ttotal: 3m 32s\tremaining: 25.2s\n",
      "894:\tlearn: 0.1478373\ttotal: 3m 32s\tremaining: 24.9s\n",
      "895:\tlearn: 0.1477608\ttotal: 3m 32s\tremaining: 24.7s\n",
      "896:\tlearn: 0.1475763\ttotal: 3m 33s\tremaining: 24.5s\n",
      "897:\tlearn: 0.1474388\ttotal: 3m 33s\tremaining: 24.2s\n",
      "898:\tlearn: 0.1473622\ttotal: 3m 33s\tremaining: 24s\n",
      "899:\tlearn: 0.1472879\ttotal: 3m 33s\tremaining: 23.8s\n",
      "900:\tlearn: 0.1472163\ttotal: 3m 34s\tremaining: 23.5s\n",
      "901:\tlearn: 0.1471250\ttotal: 3m 34s\tremaining: 23.3s\n",
      "902:\tlearn: 0.1470372\ttotal: 3m 34s\tremaining: 23s\n",
      "903:\tlearn: 0.1468860\ttotal: 3m 34s\tremaining: 22.8s\n",
      "904:\tlearn: 0.1467296\ttotal: 3m 35s\tremaining: 22.6s\n",
      "905:\tlearn: 0.1466181\ttotal: 3m 35s\tremaining: 22.3s\n",
      "906:\tlearn: 0.1465433\ttotal: 3m 35s\tremaining: 22.1s\n",
      "907:\tlearn: 0.1463674\ttotal: 3m 35s\tremaining: 21.9s\n",
      "908:\tlearn: 0.1462251\ttotal: 3m 36s\tremaining: 21.6s\n",
      "909:\tlearn: 0.1461399\ttotal: 3m 36s\tremaining: 21.4s\n",
      "910:\tlearn: 0.1460348\ttotal: 3m 36s\tremaining: 21.1s\n",
      "911:\tlearn: 0.1459366\ttotal: 3m 36s\tremaining: 20.9s\n",
      "912:\tlearn: 0.1458768\ttotal: 3m 37s\tremaining: 20.7s\n",
      "913:\tlearn: 0.1458069\ttotal: 3m 37s\tremaining: 20.4s\n",
      "914:\tlearn: 0.1457309\ttotal: 3m 37s\tremaining: 20.2s\n",
      "915:\tlearn: 0.1456535\ttotal: 3m 37s\tremaining: 20s\n",
      "916:\tlearn: 0.1455790\ttotal: 3m 37s\tremaining: 19.7s\n",
      "917:\tlearn: 0.1454706\ttotal: 3m 38s\tremaining: 19.5s\n",
      "918:\tlearn: 0.1453830\ttotal: 3m 38s\tremaining: 19.3s\n",
      "919:\tlearn: 0.1452887\ttotal: 3m 38s\tremaining: 19s\n",
      "920:\tlearn: 0.1452204\ttotal: 3m 38s\tremaining: 18.8s\n",
      "921:\tlearn: 0.1451425\ttotal: 3m 39s\tremaining: 18.5s\n",
      "922:\tlearn: 0.1449412\ttotal: 3m 39s\tremaining: 18.3s\n",
      "923:\tlearn: 0.1448730\ttotal: 3m 39s\tremaining: 18.1s\n",
      "924:\tlearn: 0.1447177\ttotal: 3m 39s\tremaining: 17.8s\n",
      "925:\tlearn: 0.1446180\ttotal: 3m 40s\tremaining: 17.6s\n",
      "926:\tlearn: 0.1445097\ttotal: 3m 40s\tremaining: 17.4s\n",
      "927:\tlearn: 0.1443128\ttotal: 3m 40s\tremaining: 17.1s\n",
      "928:\tlearn: 0.1442662\ttotal: 3m 40s\tremaining: 16.9s\n",
      "929:\tlearn: 0.1441714\ttotal: 3m 41s\tremaining: 16.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "930:\tlearn: 0.1440026\ttotal: 3m 41s\tremaining: 16.4s\n",
      "931:\tlearn: 0.1438101\ttotal: 3m 41s\tremaining: 16.2s\n",
      "932:\tlearn: 0.1436851\ttotal: 3m 41s\tremaining: 15.9s\n",
      "933:\tlearn: 0.1436318\ttotal: 3m 42s\tremaining: 15.7s\n",
      "934:\tlearn: 0.1435383\ttotal: 3m 42s\tremaining: 15.5s\n",
      "935:\tlearn: 0.1433811\ttotal: 3m 42s\tremaining: 15.2s\n",
      "936:\tlearn: 0.1432915\ttotal: 3m 42s\tremaining: 15s\n",
      "937:\tlearn: 0.1432233\ttotal: 3m 42s\tremaining: 14.7s\n",
      "938:\tlearn: 0.1431291\ttotal: 3m 43s\tremaining: 14.5s\n",
      "939:\tlearn: 0.1430451\ttotal: 3m 43s\tremaining: 14.3s\n",
      "940:\tlearn: 0.1430033\ttotal: 3m 43s\tremaining: 14s\n",
      "941:\tlearn: 0.1429165\ttotal: 3m 43s\tremaining: 13.8s\n",
      "942:\tlearn: 0.1427952\ttotal: 3m 44s\tremaining: 13.5s\n",
      "943:\tlearn: 0.1427027\ttotal: 3m 44s\tremaining: 13.3s\n",
      "944:\tlearn: 0.1425891\ttotal: 3m 44s\tremaining: 13.1s\n",
      "945:\tlearn: 0.1425223\ttotal: 3m 44s\tremaining: 12.8s\n",
      "946:\tlearn: 0.1423758\ttotal: 3m 45s\tremaining: 12.6s\n",
      "947:\tlearn: 0.1423048\ttotal: 3m 45s\tremaining: 12.4s\n",
      "948:\tlearn: 0.1422051\ttotal: 3m 45s\tremaining: 12.1s\n",
      "949:\tlearn: 0.1420608\ttotal: 3m 45s\tremaining: 11.9s\n",
      "950:\tlearn: 0.1419838\ttotal: 3m 45s\tremaining: 11.6s\n",
      "951:\tlearn: 0.1419427\ttotal: 3m 46s\tremaining: 11.4s\n",
      "952:\tlearn: 0.1418104\ttotal: 3m 46s\tremaining: 11.2s\n",
      "953:\tlearn: 0.1417188\ttotal: 3m 46s\tremaining: 10.9s\n",
      "954:\tlearn: 0.1416271\ttotal: 3m 46s\tremaining: 10.7s\n",
      "955:\tlearn: 0.1415550\ttotal: 3m 47s\tremaining: 10.4s\n",
      "956:\tlearn: 0.1414143\ttotal: 3m 47s\tremaining: 10.2s\n",
      "957:\tlearn: 0.1413804\ttotal: 3m 47s\tremaining: 9.97s\n",
      "958:\tlearn: 0.1413312\ttotal: 3m 47s\tremaining: 9.73s\n",
      "959:\tlearn: 0.1412197\ttotal: 3m 47s\tremaining: 9.49s\n",
      "960:\tlearn: 0.1411282\ttotal: 3m 48s\tremaining: 9.26s\n",
      "961:\tlearn: 0.1410738\ttotal: 3m 48s\tremaining: 9.02s\n",
      "962:\tlearn: 0.1410013\ttotal: 3m 48s\tremaining: 8.78s\n",
      "963:\tlearn: 0.1408801\ttotal: 3m 48s\tremaining: 8.54s\n",
      "964:\tlearn: 0.1407983\ttotal: 3m 49s\tremaining: 8.31s\n",
      "965:\tlearn: 0.1407365\ttotal: 3m 49s\tremaining: 8.07s\n",
      "966:\tlearn: 0.1406645\ttotal: 3m 49s\tremaining: 7.83s\n",
      "967:\tlearn: 0.1406246\ttotal: 3m 49s\tremaining: 7.59s\n",
      "968:\tlearn: 0.1405219\ttotal: 3m 49s\tremaining: 7.36s\n",
      "969:\tlearn: 0.1404515\ttotal: 3m 50s\tremaining: 7.12s\n",
      "970:\tlearn: 0.1403970\ttotal: 3m 50s\tremaining: 6.88s\n",
      "971:\tlearn: 0.1402822\ttotal: 3m 50s\tremaining: 6.64s\n",
      "972:\tlearn: 0.1402247\ttotal: 3m 50s\tremaining: 6.41s\n",
      "973:\tlearn: 0.1401652\ttotal: 3m 51s\tremaining: 6.17s\n",
      "974:\tlearn: 0.1401019\ttotal: 3m 51s\tremaining: 5.93s\n",
      "975:\tlearn: 0.1400025\ttotal: 3m 51s\tremaining: 5.69s\n",
      "976:\tlearn: 0.1399304\ttotal: 3m 51s\tremaining: 5.46s\n",
      "977:\tlearn: 0.1398543\ttotal: 3m 51s\tremaining: 5.22s\n",
      "978:\tlearn: 0.1397718\ttotal: 3m 52s\tremaining: 4.98s\n",
      "979:\tlearn: 0.1396986\ttotal: 3m 52s\tremaining: 4.74s\n",
      "980:\tlearn: 0.1396555\ttotal: 3m 52s\tremaining: 4.5s\n",
      "981:\tlearn: 0.1395861\ttotal: 3m 52s\tremaining: 4.27s\n",
      "982:\tlearn: 0.1395287\ttotal: 3m 53s\tremaining: 4.03s\n",
      "983:\tlearn: 0.1394513\ttotal: 3m 53s\tremaining: 3.79s\n",
      "984:\tlearn: 0.1392959\ttotal: 3m 53s\tremaining: 3.56s\n",
      "985:\tlearn: 0.1392289\ttotal: 3m 53s\tremaining: 3.32s\n",
      "986:\tlearn: 0.1391734\ttotal: 3m 53s\tremaining: 3.08s\n",
      "987:\tlearn: 0.1390187\ttotal: 3m 54s\tremaining: 2.84s\n",
      "988:\tlearn: 0.1389803\ttotal: 3m 54s\tremaining: 2.61s\n",
      "989:\tlearn: 0.1389169\ttotal: 3m 54s\tremaining: 2.37s\n",
      "990:\tlearn: 0.1388593\ttotal: 3m 54s\tremaining: 2.13s\n",
      "991:\tlearn: 0.1387978\ttotal: 3m 55s\tremaining: 1.9s\n",
      "992:\tlearn: 0.1386656\ttotal: 3m 55s\tremaining: 1.66s\n",
      "993:\tlearn: 0.1386002\ttotal: 3m 55s\tremaining: 1.42s\n",
      "994:\tlearn: 0.1385006\ttotal: 3m 55s\tremaining: 1.19s\n",
      "995:\tlearn: 0.1383953\ttotal: 3m 56s\tremaining: 948ms\n",
      "996:\tlearn: 0.1382475\ttotal: 3m 56s\tremaining: 711ms\n",
      "997:\tlearn: 0.1381695\ttotal: 3m 56s\tremaining: 474ms\n",
      "998:\tlearn: 0.1381108\ttotal: 3m 56s\tremaining: 237ms\n",
      "999:\tlearn: 0.1380403\ttotal: 3m 57s\tremaining: 0us\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-4845bd363073>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcbc_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_pca_mnist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy Score:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cbc = CatBoostClassifier()\n",
    "cbc.fit(X_train_pca_mnist, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1296    0    2    0    2    2    7    0    3    0]\n",
      " [   0 1574   10    2    2    4    0    2    5    5]\n",
      " [   6    4 1283   12    7    2    6   12   14    2]\n",
      " [   1    4   13 1347    1   21    3    8   20    9]\n",
      " [   2    5    4    1 1290    0   15    4    6   35]\n",
      " [   6    1    4   21    4 1216   14    2   10    2]\n",
      " [   6    1    6    0    3   13 1364    0    3    1]\n",
      " [   3    6   12    3   14    2    0 1393    1   27]\n",
      " [   1   10    9   25    5   14    7    5 1304   10]\n",
      " [   4    6    5   21   36    6    1   23    9 1308]]\n",
      "Accuracy Score:\n",
      "0.9553571428571429\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cbc_pred = cbc.predict(X_test_pca_mnist)\n",
    "print(metrics.confusion_matrix(y_test, cbc_pred))\n",
    "print('Accuracy Score:')\n",
    "print(metrics.accuracy_score(y_test, cbc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-f3f807cb3ac8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"k-means++\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pca_mnist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kmeans = KMeans(init=\"k-means++\", n_clusters=10, random_state=0)\n",
    "kmeans.fit(X_train_pca_mnist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   4   58 4100    0  998    9    9  146   34  233]\n",
      " [2817    6    0 3406    7   10    9    5    7    6]\n",
      " [ 365  174   46  320  201   71 3912  112  184  257]\n",
      " [  47  831   20  347  364   39  183   27  160 3696]\n",
      " [ 194   14    5  130  241 1762   21  139 2955    1]\n",
      " [ 231  938   48  111 1417  182    6   54  331 1715]\n",
      " [  38   12   59  147 1694    4   46 3389   59   31]\n",
      " [ 259   17   18  299    7 3549   43    3 1632    5]\n",
      " [ 261 3291   29  265  226  150   39   43  163  968]\n",
      " [  81   75   43  201   22 2297   15   16 2723   66]]\n",
      "Accuracy Score:\n",
      "0.019714285714285715\n"
     ]
    }
   ],
   "source": [
    "kmeans_pred = kmeans.predict(X_train_pca_mnist)\n",
    "print(metrics.confusion_matrix(y_train, kmeans_pred))\n",
    "print('Accuracy Score:')\n",
    "print(metrics.accuracy_score(y_train, kmeans_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBSCAN(algorithm='auto', eps=2.4, leaf_size=30, metric='euclidean',\n",
       "       metric_params=None, min_samples=100, n_jobs=None, p=None)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "dbscan = DBSCAN(eps=2.4, min_samples=100)\n",
    "dbscan.fit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [1312    0    0    0    0    0    0    0    0    0    0]\n",
      " [1604    0    0    0    0    0    0    0    0    0    0]\n",
      " [1348    0    0    0    0    0    0    0    0    0    0]\n",
      " [1427    0    0    0    0    0    0    0    0    0    0]\n",
      " [1362    0    0    0    0    0    0    0    0    0    0]\n",
      " [1280    0    0    0    0    0    0    0    0    0    0]\n",
      " [1397    0    0    0    0    0    0    0    0    0    0]\n",
      " [1461    0    0    0    0    0    0    0    0    0    0]\n",
      " [1390    0    0    0    0    0    0    0    0    0    0]\n",
      " [1419    0    0    0    0    0    0    0    0    0    0]]\n",
      "Accuracy Score:\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "dbscan_pred = dbscan.fit_predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test, dbscan_pred))\n",
    "print('Accuracy Score:')\n",
    "print(metrics.accuracy_score(y_test, dbscan_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
