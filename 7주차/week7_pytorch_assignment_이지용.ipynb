{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"week7_pytorch_assignment_이지용.ipynb","provenance":[{"file_id":"109CA2coS0naq0ZAkDUROn73a1oP52j4W","timestamp":1584102627500}],"collapsed_sections":[],"mount_file_id":"1tumzN0eLv1_8TAe6rjEmPf3mXkvFBO6o","authorship_tag":"ABX9TyOFbEo9saJxPj5AgOUYZHBc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"gHxpKCOgwCG3","colab_type":"code","outputId":"d25d7318-70ac-4d8d-c95c-59e28a499154","executionInfo":{"status":"ok","timestamp":1584433807471,"user_tz":-540,"elapsed":1070,"user":{"displayName":"이지용","photoUrl":"","userId":"08607588663598695094"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["cd drive/My Drive/Colab Notebooks"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZN9PW4cGwCM0","colab_type":"code","outputId":"5301786a-f473-4527-b3bd-52f8c2e15764","executionInfo":{"status":"ok","timestamp":1584433812527,"user_tz":-540,"elapsed":3068,"user":{"displayName":"이지용","photoUrl":"","userId":"08607588663598695094"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["!ls"],"execution_count":8,"outputs":[{"output_type":"stream","text":["BWeight.md5\t       test_df.csv\ttrain_df.csv.zip\n","radam_submission.csv   test_df.csv.zip\tweek7_keras_assignment_이지용.ipynb\n","sample_submission.csv  train_df.csv\tweek7_pytorch_assignment_이지용.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NrY62GWlwCJN","colab_type":"code","colab":{}},"source":["import pandas as pd\n","sample_submission = pd.read_csv(\"sample_submission.csv\")\n","train = pd.read_csv(\"train_df.csv\")\n","test = pd.read_csv(\"test_df.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kxjF27J2wWVS","colab_type":"code","colab":{}},"source":["X = train.iloc[:,1:].values / 255\n","y = train.iloc[:,0].values\n","X_test = test.iloc[:,1:].values / 255"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0hUnceljjrYe","colab_type":"code","outputId":"d207af28-c0f2-4401-f7c1-a1e500170bb1","executionInfo":{"status":"ok","timestamp":1584433824245,"user_tz":-540,"elapsed":14126,"user":{"displayName":"이지용","photoUrl":"","userId":"08607588663598695094"}},"colab":{"base_uri":"https://localhost:8080/","height":247}},"source":["pd.DataFrame(X).head()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>...</th>\n","      <th>744</th>\n","      <th>745</th>\n","      <th>746</th>\n","      <th>747</th>\n","      <th>748</th>\n","      <th>749</th>\n","      <th>750</th>\n","      <th>751</th>\n","      <th>752</th>\n","      <th>753</th>\n","      <th>754</th>\n","      <th>755</th>\n","      <th>756</th>\n","      <th>757</th>\n","      <th>758</th>\n","      <th>759</th>\n","      <th>760</th>\n","      <th>761</th>\n","      <th>762</th>\n","      <th>763</th>\n","      <th>764</th>\n","      <th>765</th>\n","      <th>766</th>\n","      <th>767</th>\n","      <th>768</th>\n","      <th>769</th>\n","      <th>770</th>\n","      <th>771</th>\n","      <th>772</th>\n","      <th>773</th>\n","      <th>774</th>\n","      <th>775</th>\n","      <th>776</th>\n","      <th>777</th>\n","      <th>778</th>\n","      <th>779</th>\n","      <th>780</th>\n","      <th>781</th>\n","      <th>782</th>\n","      <th>783</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 784 columns</p>\n","</div>"],"text/plain":["   0    1    2    3    4    5    6    ...  777  778  779  780  781  782  783\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","\n","[5 rows x 784 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"mHZxx1n9j88y","colab_type":"code","outputId":"8f17375e-2dd2-4f09-a2f4-aa01d79f43e4","executionInfo":{"status":"ok","timestamp":1584433824246,"user_tz":-540,"elapsed":13956,"user":{"displayName":"이지용","photoUrl":"","userId":"08607588663598695094"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["y"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([7, 8, 7, ..., 9, 4, 3])"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"1MN_kvA1wWXl","colab_type":"code","colab":{}},"source":["from torch.utils.data import Dataset, DataLoader\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, X, y, transform=None):\n","        self.X = X\n","        self.y = y\n","        self.transform = transform\n","    \n","    def __len__(self):\n","        return len(self.X)\n","    \n","    def __getitem__(self, idx):\n","        X = self.X[idx]\n","        y = self.y[idx]\n","        return X, y\n","\n","class TestDataset(Dataset):\n","    def __init__(self, X, y, transform=None):\n","        self.X = X\n","        self.y = y\n","        self.transform = transform\n","    \n","    def __len__(self):\n","        return len(self.X)\n","    \n","    def __getitem__(self, idx):\n","        X = self.X[idx]\n","        return X"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lcAhKfuOkxuC","colab_type":"text"},"source":["데이터를 batch 단위로 입력시키기 위한 batch iterator 생성  \n","모델의 파라미터를 업데이트 시키기 방법으로 gradient descent 방법 등을 사용합니다. 이 때 업데이트의 주기를  \n","1) 전체 데이터를 다 보고나서    \n","2) 데이터 하나하나를 볼 때마다  \n","3) 그 중간 단위로 batch size 만큼의 데이터를 보고나서 로 구분지을 수 있습니다.  \n","가장 결과가 잘 나오고, 효율적인 방법인 \n","3)을 주로 사용하므로 batch iterator을 만들 필요가 있겠죠.  \n","출처 : https://medium.com/@inmoonlight/pytorch%EB%A1%9C-%EB%94%A5%EB%9F%AC%EB%8B%9D%ED%95%98%EA%B8%B0-cnn-62a9326111ae"]},{"cell_type":"code","metadata":{"id":"-thP0hU3wWcV","colab_type":"code","colab":{}},"source":["traindataloader = DataLoader(TrainDataset(X, y), batch_size=128, shuffle=True, num_workers=4)\n","testdataloader = DataLoader(TestDataset(X_test, y=None), batch_size=4, shuffle=False, num_workers=4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LMlbp_1snCmY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oGdH3x0zoZ4A","colab_type":"text"},"source":["class torch.nn.Module은 \\_\\_init\\_\\_ 과 forward를 정의해주어야 한다.  \n","Applies a linear transformation to the incoming data: y = xA^T + by=xA \n","T\n"," +b"]},{"cell_type":"code","metadata":{"id":"rkJDBCsKwWan","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(784, 512)                  # 입력 픽셀 수가 784개\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, 128)\n","        self.fc4 = nn.Linear(128, 10)                   # 클래스는 10개\n","        self.elu = nn.ELU()\n","        self.dropout1 = torch.nn.Dropout(p=0.2)\n","        self.dropout2 = torch.nn.Dropout(p=0.2)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.fc2(F.relu(x))\n","        x = self.dropout1(x)\n","        x = self.fc3(self.elu(x))\n","        x = self.dropout2(x)\n","        x = self.fc4(x)\n","        return x\n","\n","    # weight initialization\n","    def init_weights(m):\n","      if type(m) == nn.Linear:\n","        torch.nn.init.kaiming_uniform_(tensor, a=0, mode='fan_in', nonlinearity='relu')  #he initialization\n","\n","net = Net()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IudqttkawcQl","colab_type":"code","outputId":"5d130fbf-bebd-430f-ebdb-77284f6076d5","executionInfo":{"status":"ok","timestamp":1584433830247,"user_tz":-540,"elapsed":889,"user":{"displayName":"이지용","photoUrl":"","userId":"08607588663598695094"}},"colab":{"base_uri":"https://localhost:8080/","height":181}},"source":["net"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Net(\n","  (fc1): Linear(in_features=784, out_features=512, bias=True)\n","  (fc2): Linear(in_features=512, out_features=256, bias=True)\n","  (fc3): Linear(in_features=256, out_features=128, bias=True)\n","  (fc4): Linear(in_features=128, out_features=10, bias=True)\n","  (elu): ELU(alpha=1.0)\n","  (dropout1): Dropout(p=0.2, inplace=False)\n","  (dropout2): Dropout(p=0.2, inplace=False)\n",")"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"TdXGbK_xmHWy","colab_type":"text"},"source":["손실함수와 최적화 기법 설정"]},{"cell_type":"code","metadata":{"id":"12NJoLQ0wcTK","colab_type":"code","colab":{}},"source":["import torch.optim as optim\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","#optimizer = optim.Adagrad(net.parameters(), lr=2e-3, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n","#optimizer = optim.Adam(net.parameters(), Ir=2e-3, weight_decay=1e-3)\n","optimizer = optim.SGD(net.parameters(), lr=2e-3, momentum=0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"32iceinDjl68","colab_type":"text"},"source":["디바이스를 GPU로 설정한다"]},{"cell_type":"code","metadata":{"id":"krKwo5stwcYR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"d1d7604e-1563-4c3e-e679-8b7747a27cb9","executionInfo":{"status":"ok","timestamp":1584433833680,"user_tz":-540,"elapsed":1169,"user":{"displayName":"이지용","photoUrl":"","userId":"08607588663598695094"}}},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"4-KvuGtiwcad","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":181},"outputId":"19a6b64a-d5cc-4f35-86a1-1a730eddef85","executionInfo":{"status":"ok","timestamp":1584433844228,"user_tz":-540,"elapsed":11287,"user":{"displayName":"이지용","photoUrl":"","userId":"08607588663598695094"}}},"source":["net.to(device)"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Net(\n","  (fc1): Linear(in_features=784, out_features=512, bias=True)\n","  (fc2): Linear(in_features=512, out_features=256, bias=True)\n","  (fc3): Linear(in_features=256, out_features=128, bias=True)\n","  (fc4): Linear(in_features=128, out_features=10, bias=True)\n","  (elu): ELU(alpha=1.0)\n","  (dropout1): Dropout(p=0.2, inplace=False)\n","  (dropout2): Dropout(p=0.2, inplace=False)\n",")"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"WEe_y2XuwcfL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"2b53a58c-8722-423d-dc1b-58045982e52b","executionInfo":{"status":"ok","timestamp":1584434609030,"user_tz":-540,"elapsed":165533,"user":{"displayName":"이지용","photoUrl":"","userId":"08607588663598695094"}}},"source":["num_epochs = 100\n","for epoch in range(num_epochs):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(traindataloader):\n","        inputs, labels = data\n","        inputs = torch.tensor(inputs, device=device).float()\n","        labels = torch.tensor(labels, device=device)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","        # print(type(inputs), type(labels), type(outputs))\n","        # forward + backward + optimize\n","        outputs = net(inputs)\n","        # print(type(inputs), type(labels), type(outputs))\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        # print statistics\n","        running_loss += loss.item()\n","    print(\"Epoch : {} loss: {}\".format(epoch, running_loss))\n","print('Finished Training')"],"execution_count":29,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n"],"name":"stderr"},{"output_type":"stream","text":["Epoch : 0 loss: 0.32470881193876266\n","Epoch : 1 loss: 0.31328876316547394\n","Epoch : 2 loss: 0.29739875346422195\n","Epoch : 3 loss: 0.2869708128273487\n","Epoch : 4 loss: 0.28977905213832855\n","Epoch : 5 loss: 0.2763303965330124\n","Epoch : 6 loss: 0.2747499383985996\n","Epoch : 7 loss: 0.3003668934106827\n","Epoch : 8 loss: 0.27326393127441406\n","Epoch : 9 loss: 0.2536405436694622\n","Epoch : 10 loss: 0.2886468879878521\n","Epoch : 11 loss: 0.286019753664732\n","Epoch : 12 loss: 0.2657979018986225\n","Epoch : 13 loss: 0.272006556391716\n","Epoch : 14 loss: 0.26823708787560463\n","Epoch : 15 loss: 0.28066450357437134\n","Epoch : 16 loss: 0.270059235394001\n","Epoch : 17 loss: 0.24658559262752533\n","Epoch : 18 loss: 0.2478296086192131\n","Epoch : 19 loss: 0.257940661162138\n","Epoch : 20 loss: 0.2719881907105446\n","Epoch : 21 loss: 0.2408161349594593\n","Epoch : 22 loss: 0.24821965023875237\n","Epoch : 23 loss: 0.23317361623048782\n","Epoch : 24 loss: 0.2507300339639187\n","Epoch : 25 loss: 0.24726209044456482\n","Epoch : 26 loss: 0.24584103003144264\n","Epoch : 27 loss: 0.23761586099863052\n","Epoch : 28 loss: 0.2432689443230629\n","Epoch : 29 loss: 0.2287651188671589\n","Epoch : 30 loss: 0.23866157233715057\n","Epoch : 31 loss: 0.22613533213734627\n","Epoch : 32 loss: 0.24449148401618004\n","Epoch : 33 loss: 0.21239466965198517\n","Epoch : 34 loss: 0.24698864668607712\n","Epoch : 35 loss: 0.21391073986887932\n","Epoch : 36 loss: 0.213096484541893\n","Epoch : 37 loss: 0.2172248624265194\n","Epoch : 38 loss: 0.21847813576459885\n","Epoch : 39 loss: 0.20993101596832275\n","Epoch : 40 loss: 0.22674694284796715\n","Epoch : 41 loss: 0.20730196312069893\n","Epoch : 42 loss: 0.2310931235551834\n","Epoch : 43 loss: 0.2190263532102108\n","Epoch : 44 loss: 0.20918850600719452\n","Epoch : 45 loss: 0.20190038532018661\n","Epoch : 46 loss: 0.20138610899448395\n","Epoch : 47 loss: 0.19797362945973873\n","Epoch : 48 loss: 0.2150716334581375\n","Epoch : 49 loss: 0.20103029906749725\n","Epoch : 50 loss: 0.19321198761463165\n","Epoch : 51 loss: 0.20481206104159355\n","Epoch : 52 loss: 0.18799374252557755\n","Epoch : 53 loss: 0.18015775829553604\n","Epoch : 54 loss: 0.18568755686283112\n","Epoch : 55 loss: 0.19200507551431656\n","Epoch : 56 loss: 0.1977957785129547\n","Epoch : 57 loss: 0.18825308233499527\n","Epoch : 58 loss: 0.19044414907693863\n","Epoch : 59 loss: 0.17704835906624794\n","Epoch : 60 loss: 0.18545763194561005\n","Epoch : 61 loss: 0.1724809594452381\n","Epoch : 62 loss: 0.17316308617591858\n","Epoch : 63 loss: 0.18455954268574715\n","Epoch : 64 loss: 0.17267278209328651\n","Epoch : 65 loss: 0.16392331942915916\n","Epoch : 66 loss: 0.18681595847010612\n","Epoch : 67 loss: 0.17504943162202835\n","Epoch : 68 loss: 0.18269113823771477\n","Epoch : 69 loss: 0.17257993295788765\n","Epoch : 70 loss: 0.1715545654296875\n","Epoch : 71 loss: 0.16907033324241638\n","Epoch : 72 loss: 0.17582054808735847\n","Epoch : 73 loss: 0.18836547434329987\n","Epoch : 74 loss: 0.15278824418783188\n","Epoch : 75 loss: 0.15607695281505585\n","Epoch : 76 loss: 0.16115891933441162\n","Epoch : 77 loss: 0.1556033156812191\n","Epoch : 78 loss: 0.1956799253821373\n","Epoch : 79 loss: 0.18350288644433022\n","Epoch : 80 loss: 0.1630161926150322\n","Epoch : 81 loss: 0.1680789701640606\n","Epoch : 82 loss: 0.15123077481985092\n","Epoch : 83 loss: 0.17716864496469498\n","Epoch : 84 loss: 0.1871679462492466\n","Epoch : 85 loss: 0.15198984369635582\n","Epoch : 86 loss: 0.15640638023614883\n","Epoch : 87 loss: 0.1754092201590538\n","Epoch : 88 loss: 0.15374039486050606\n","Epoch : 89 loss: 0.15642619132995605\n","Epoch : 90 loss: 0.15046707913279533\n","Epoch : 91 loss: 0.15127834305167198\n","Epoch : 92 loss: 0.16169201210141182\n","Epoch : 93 loss: 0.16307660937309265\n","Epoch : 94 loss: 0.14664318785071373\n","Epoch : 95 loss: 0.13811533525586128\n","Epoch : 96 loss: 0.1668318249285221\n","Epoch : 97 loss: 0.14635979011654854\n","Epoch : 98 loss: 0.14218026772141457\n","Epoch : 99 loss: 0.1384725421667099\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vvd6cfyewcc3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":74},"outputId":"53e2789c-c11c-4ad2-a879-4d6041742856","executionInfo":{"status":"ok","timestamp":1584434623556,"user_tz":-540,"elapsed":7277,"user":{"displayName":"이지용","photoUrl":"","userId":"08607588663598695094"}}},"source":["correct = 0\n","total = 0\n","net.eval()\n","preds = []\n","with torch.no_grad():\n","    for data in testdataloader:\n","        inputs = data\n","        inputs = torch.tensor(inputs, device=device).float()\n","        outputs = net(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        for pred in predicted:\n","          preds.append(pred.cpu().numpy())"],"execution_count":30,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"u7x5BahrwjjX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":199},"outputId":"a6e8063f-477f-4e0e-d306-0e0f451bc426","executionInfo":{"status":"ok","timestamp":1584434623557,"user_tz":-540,"elapsed":6928,"user":{"displayName":"이지용","photoUrl":"","userId":"08607588663598695094"}}},"source":["preds[:10]"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array(8),\n"," array(0),\n"," array(5),\n"," array(3),\n"," array(8),\n"," array(1),\n"," array(9),\n"," array(6),\n"," array(6),\n"," array(0)]"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"Re8t2rZSwjoD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"79a16db1-f72f-4eaf-bc6d-d7c695e0eac6","executionInfo":{"status":"ok","timestamp":1584434623558,"user_tz":-540,"elapsed":6232,"user":{"displayName":"이지용","photoUrl":"","userId":"08607588663598695094"}}},"source":["import numpy as np\n","preds = np.array(preds)\n","print(preds.shape)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["(18000,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lsfYPP0rwjqh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":198},"outputId":"af249ade-507a-4532-a232-9b0266c07a4e","executionInfo":{"status":"ok","timestamp":1584434623559,"user_tz":-540,"elapsed":5534,"user":{"displayName":"이지용","photoUrl":"","userId":"08607588663598695094"}}},"source":["sample_submission[\"Category\"] = pd.Series(preds)\n","sample_submission.head()"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>57808</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4960</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>35755</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>15543</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>48968</td>\n","      <td>8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Id  Category\n","0  57808         8\n","1   4960         0\n","2  35755         5\n","3  15543         3\n","4  48968         8"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"R7_o3yJbwjvC","colab_type":"code","colab":{}},"source":["sample_submission.to_csv(\"torch_submission.csv\", index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lVnf4y2kwjtV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YwKKW3Fgwjl3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}